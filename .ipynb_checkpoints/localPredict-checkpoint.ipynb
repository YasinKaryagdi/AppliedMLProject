{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9f0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a11421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 200\n",
    "#model_name = \"efficientnetV2s\" \n",
    "#model_path = \"finetuned_models/efficientnetV2s_nofreeze_aug.pth\"\n",
    "\n",
    "curr_seed = 0\n",
    "model_name = \"MODERNRES\" \n",
    "model_path = f\"Test/MODERNRES_{curr_seed}.pth\"\n",
    "\n",
    "#model_name = \"ensemble\" \n",
    "#model_path = \"Test/ensemble.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a68376",
   "metadata": {},
   "source": [
    "Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee1b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "        self.activation = nn.ReLU()  # <- changed back from SiLU\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        # Squeeze: global average pooling\n",
    "        y = x.mean(dim=(2, 3))           # (B, C)\n",
    "        # Excitation: MLP\n",
    "        y = self.fc2(self.activation(self.fc1(y)))  # (B, C)\n",
    "        y = self.sigmoid(y).view(b, c, 1, 1)\n",
    "        # Scale: multiply original feature map\n",
    "        return x * y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c756f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, use_se=False, use_pool=False):\n",
    "        super().__init__()\n",
    "        self.use_se = use_se\n",
    "        self.use_pool = use_pool\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        self.shortcut = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "        self.act = nn.SiLU(inplace=True)\n",
    "        if use_pool:\n",
    "            self.pool = nn.MaxPool2d(2)\n",
    "        if use_se:\n",
    "            self.se = SEBlock(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = self.act(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "\n",
    "        if self.use_se:\n",
    "            out = self.se(out)\n",
    "\n",
    "        out = self.act(out)\n",
    "        if self.use_pool:\n",
    "            out = self.pool(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce03c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODERNRES(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super().__init__()\n",
    "\n",
    "        # Stage-level residual blocks\n",
    "        self.stage1 = ResidualBlock(3, 32, use_se=True)\n",
    "        self.stage2 = ResidualBlock(32, 64, use_se=True)\n",
    "        self.stage3 = ResidualBlock(64, 96, use_se=True)\n",
    "        self.stage4 = ResidualBlock(96, 128, use_se=True)\n",
    "        self.stage5 = ResidualBlock(128, 160, use_se=True)\n",
    "\n",
    "        # Classifier\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(160, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x - 0.5) * 2.0  # normalize to [-1, 1]\n",
    "\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17cfcb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, modelList):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList(modelList)\n",
    "        self.classifier = nn.Linear(200 * len(modelList), 200)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for model in self.models:\n",
    "            outputs.append(model(x))\n",
    "\n",
    "        x_cat = torch.cat(outputs, dim=1)\n",
    "        x_cat = self.dropout(x_cat)\n",
    "        out = self.classifier(x_cat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e732cc6d",
   "metadata": {},
   "source": [
    "Code used for loading and predicting test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b7da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, csv_file, base_dir, transform=None, return_id=False):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.base_dir = base_dir\n",
    "        self.transform = transform\n",
    "        self.return_id = return_id  # Useful for test set where no labels exist\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # extract fields\n",
    "        img_id = row['id'] if self.return_id else None\n",
    "        relative_path = row['image_path'].lstrip('/')  # safe\n",
    "        label = row['label'] - 1   # shift to 0-based indexing\n",
    "\n",
    "        # build full path\n",
    "        img_path = os.path.join(self.base_dir, relative_path)\n",
    "\n",
    "        # load\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # optionally return id\n",
    "        if self.return_id:\n",
    "            return image, label, img_id\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d861dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "    ids_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, img_ids in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            #Re-add 1 to label to give right predictions\n",
    "            preds_list.extend(preds.cpu().numpy()+1)\n",
    "            ids_list.extend(img_ids.numpy())\n",
    "\n",
    "    return ids_list, preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5da30fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09768f0f",
   "metadata": {},
   "source": [
    "Genererate submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d52dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_305365/2940160519.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  finetuned_model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"efficientnetV2s\":\n",
    "  \"\"\"EfficientnetV2s\"\"\"\n",
    "  efficientnet_v2_s_weights = models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "  model_transforms = efficientnet_v2_s_weights.transforms()\n",
    "  finetuned_model = models.efficientnet_v2_s()\n",
    "  num_ftrs = finetuned_model.classifier[1].in_features\n",
    "  finetuned_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "  finetuned_model.num_classes = num_classes\n",
    "  finetuned_model.load_state_dict(torch.load(model_path))\n",
    "  finetuned_model.to(device)\n",
    "elif model_name == \"MODERNRES\":\n",
    "  \"\"\"Our model\"\"\"\n",
    "  transformations = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Resize((size)),\n",
    "  transforms.Normalize(mean = (0.5,0.5,0.5), std = (0.5,0.5,0.5))\n",
    "  ])\n",
    "  model_transform = transformations\n",
    "  finetuned_model = MODERNRES(num_classes=num_classes)\n",
    "  finetuned_model.load_state_dict(torch.load(model_path))\n",
    "  finetuned_model.to(device)\n",
    "elif model_name == \"ensemble\":\n",
    "  \"\"\"Ensemble of 7 MODERNRES models\"\"\"\n",
    "  modelList = []\n",
    "  model_path_base = \"Test/MODERNRES\"\n",
    "  for i in range(7):\n",
    "      model = MODERNRES(num_classes=num_classes)\n",
    "      model_path_i = model_path_base + f'_{i+1}.pth'\n",
    "      model.load_state_dict(torch.load(model_path_i))\n",
    "      model.to(device)\n",
    "      modelList.append(model)\n",
    "  finetuned_model = EnsembleModel(modelList)\n",
    "  finetuned_model.load_state_dict(torch.load(model_path))\n",
    "  finetuned_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d42ffe38",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Get Test set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dirpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maml-2025-feathers-in-focus\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m CSVDataset(\n\u001b[1;32m      4\u001b[0m     csv_file\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maml-2025-feathers-in-focus/test_images_path.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     base_dir\u001b[38;5;241m=\u001b[39m dirpath ,\n\u001b[0;32m----> 6\u001b[0m     transform \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_transforms\u001b[49m,\n\u001b[1;32m      7\u001b[0m     return_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m test_image_ids \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#Create dataloader\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_transforms' is not defined"
     ]
    }
   ],
   "source": [
    "#Get Test set\n",
    "dirpath = \"aml-2025-feathers-in-focus\"\n",
    "test_dataset = CSVDataset(\n",
    "    csv_file= \"aml-2025-feathers-in-focus/test_images_path.csv\",\n",
    "    base_dir= dirpath ,\n",
    "    transform = model_transforms,\n",
    "    return_id=True\n",
    ")\n",
    "test_image_ids = test_dataset.df['id'].tolist()\n",
    "#Create dataloader\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ensemble prediction\n",
    "test_ids, test_preds = predict(finetuned_model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac88c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate submission.csv for ensemble\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"label\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(f\"submissions/{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2612d-8c1b-481d-a886-d05225c5432a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-wsl)",
   "language": "python",
   "name": "torch-wsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
