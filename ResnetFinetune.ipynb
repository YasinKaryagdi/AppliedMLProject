{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNs5acFZ40jJhS8+nmPmMlM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasinKaryagdi/AppliedMLProject/blob/ResnetColab/ResnetFinetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKm4ZAjDpgth"
      },
      "outputs": [],
      "source": [
        "!git clone https://YasinKaryagdi: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@github.com/YasinKaryagdi/AppliedMLProject.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining model and training variables\n",
        "#model\n",
        "model_name = 'resnet'\n",
        "#training batchsize\n",
        "train_batch_size = 32\n",
        "#validation & testing batchsize\n",
        "val_batch_size = 64\n",
        "#Epochs\n",
        "num_epochs = 40\n",
        "#feature extraction option\n",
        "feature_extract = False\n",
        "#resize to:\n",
        "size = (256,256)\n",
        "#use pretrained or not\n",
        "use_pretrained = True\n",
        "classes = np.load(image_classes, allow_pickle=True).item()\n",
        "num_classes = len(classes)\n",
        "#train-test split\n",
        "split = 0.85"
      ],
      "metadata": {
        "id": "_pU3X7eQ338C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from imutils import paths\n",
        "from pathlib import Path\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "Jpb3XBcdyvwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CSVDataset(Dataset):\n",
        "    def __init__(self, csv_file, base_dir, transform=None, return_id=False):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.base_dir = base_dir\n",
        "        self.transform = transform\n",
        "        self.return_id = return_id  # Useful for test set where no labels exist\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # extract fields\n",
        "        img_id = row['id'] if self.return_id else None\n",
        "        relative_path = row['image_path'].lstrip('/')  # safe\n",
        "        label = row['label'] - 1   # shift to 0-based indexing\n",
        "\n",
        "        # build full path\n",
        "        img_path = os.path.join(self.base_dir, relative_path)\n",
        "\n",
        "        # load\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # transform\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # optionally return id\n",
        "        if self.return_id:\n",
        "            return image, label, img_id\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "L3-GYuBXHV6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "id": "UNhVRp2SZVX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,\n",
        "                train_loader,\n",
        "                val_loader,\n",
        "                criterion,\n",
        "                optimizer,\n",
        "                schedular=None,\n",
        "                num_epochs=10,\n",
        "                device=\"cuda\"):\n",
        "    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n",
        "    since = time.time()\n",
        "    model.to(device)\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    val_acc_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "        for phase in ['train', 'val']:\n",
        "              if phase == 'train':\n",
        "                  model.train()  # Set model to training mode\n",
        "              else:\n",
        "                  model.eval()   # Set model to evaluate mode\n",
        "\n",
        "              running_loss = 0.0\n",
        "              running_corrects = 0\n",
        "\n",
        "              # Iterate over data.\n",
        "              for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "                  inputs = inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "\n",
        "                  # zero the parameter gradients\n",
        "                  optimizer.zero_grad()\n",
        "\n",
        "                  # forward\n",
        "                  # track history if only in train\n",
        "                  with torch.set_grad_enabled(phase == 'train'):\n",
        "                      outputs = model(inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                      # backward + optimize only if in training phase\n",
        "                      if phase == 'train':\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "                  # statistics\n",
        "                  running_loss += loss.item() * inputs.size(0)\n",
        "                  running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "              epoch_loss = running_loss / len(dataloaders_dict[phase].dataset)\n",
        "              epoch_acc = running_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "              print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "              # deep copy the model\n",
        "              if phase == 'val' and epoch_acc > best_acc:\n",
        "                  best_acc = epoch_acc\n",
        "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "              if phase == 'val':\n",
        "                  val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n"
      ],
      "metadata": {
        "id": "YseV73jKZVN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = Path.cwd()\n",
        "gitpath = cwd / \"AppliedMLProject\"\n",
        "dirpath = gitpath / \"aml-2025-feathers-in-focus\"\n",
        "train_images_csv = dirpath / \"train_images.csv\"\n",
        "train_images_folder = dirpath / \"train_images\"\n",
        "image_classes = dirpath / \"class_names.npy\"\n"
      ],
      "metadata": {
        "id": "NaI9baZX_ab5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define some standard transformations\n",
        "transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((size)),\n",
        "    transforms.Normalize(mean = (0.5,0.5,0.5), std = (0.5,0.5,0.5))\n",
        "    ])\n",
        "transformations_resnet = models.ResNet152_Weights.IMAGENET1K_V1.transforms()\n",
        "## Probably better to follow the original resnet transformations\n",
        "#See: (model.ResNet152_Weights.IMAGENET1K_V1.transforms)"
      ],
      "metadata": {
        "id": "8f7j0yqN9Upj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = CSVDataset(\n",
        "    csv_file=str(dirpath / \"train_images.csv\"),\n",
        "    base_dir=str(dirpath),\n",
        "    transform = transformations_resnet,\n",
        "    return_id=False\n",
        ")\n",
        "loader = DataLoader(full_dataset, batch_size=train_batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "l-tCV3MxO05B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if it does what I want it to\n",
        "# 1. Check dataset length\n",
        "print(f\"Dataset size: {len(full_dataset)}\")\n",
        "\n",
        "# 2. Get a single sample\n",
        "image, label = full_dataset[0]\n",
        "print(f\"Single image shape: {image.shape}\")  # Should be [3, 224, 224]\n",
        "print(f\"Single image type: {type(image)}\")   # Should be torch.Tensor\n",
        "print(f\"Single label: {label}\")              # Should be an integer\n",
        "print(f\"Label type: {type(label)}\")          # Should be int or numpy.int64\n",
        "\n",
        "# 3. Check a batch from the DataLoader\n",
        "batch_images, batch_labels = next(iter(loader))\n",
        "print(f\"\\nBatch images shape: {batch_images.shape}\")  # Should be [32, 3, 224, 224]\n",
        "print(f\"Batch images type: {type(batch_images)}\")     # Should be torch.Tensor\n",
        "print(f\"Batch images dtype: {batch_images.dtype}\")    # Should be torch.float32\n",
        "print(f\"Batch labels shape: {batch_labels.shape}\")    # Should be [32]\n",
        "print(f\"Batch labels type: {type(batch_labels)}\")     # Should be torch.Tensor\n",
        "print(f\"Batch labels dtype: {batch_labels.dtype}\")    # Could be torch.int64"
      ],
      "metadata": {
        "id": "gwTdcbP7H8Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "if model_name == \"resnet\":\n",
        "  \"\"\"Resnet152\"\"\"\n",
        "  ResNet_Weights = models.ResNet152_Weights.DEFAULT\n",
        "  transforms_resnet = ResNet_Weights.transforms()\n",
        "  if use_pretrained:\n",
        "    model_ft = models.resnet152(weights=ResNet_Weights.IMAGENET1K_V1)\n",
        "  else:\n",
        "    model_ft = models.resnet152()\n",
        "  num_ftrs = model_ft.fc.in_features\n",
        "  model_ft.fc = nn.Linear(num_ftrs, num_classes)"
      ],
      "metadata": {
        "id": "FqSjkmbPIWfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-validation split\n",
        "# Split into train (85%) and validation (15%)\n",
        "train_size = int(split * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(\n",
        "    full_dataset,\n",
        "    [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(8)\n",
        ")"
      ],
      "metadata": {
        "id": "i4fYskKDSYsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "2vCiR-hbVSTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "DartSzDJXDPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#put model on device\n",
        "model_ft = model_ft.to(device)"
      ],
      "metadata": {
        "id": "w-W26P52XRB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gather optimizable parameters\n",
        "params_to_update = model_ft.parameters()\n",
        "#Design optimzer\n",
        "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "# Setup the loss func\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "1pT9gfszYnX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate\n",
        "model_trained, hist = train_model(model_ft,\n",
        "                            train_loader,\n",
        "                            val_loader,\n",
        "                            criterion,\n",
        "                            optimizer,\n",
        "                            schedular=None,\n",
        "                            num_epochs=num_epochs,\n",
        "                            device=device)"
      ],
      "metadata": {
        "id": "Prs-oDveZHBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_trained.state_dict(), \"best_model.pth\")"
      ],
      "metadata": {
        "id": "sU_IyDNmtbKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict(model, test_loader, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    preds_list = []\n",
        "    ids_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, img_ids in tqdm(test_loader):\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            #Readd 1 to label to give right predictions\n",
        "            preds_list.extend(preds.cpu().numpy()+1)\n",
        "            ids_list.extend(img_ids.numpy())\n",
        "\n",
        "    return ids_list, preds_list"
      ],
      "metadata": {
        "id": "zusGMHLAuFWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Test set\n",
        "test_dataset = CSVDataset(\n",
        "    csv_file=str(dirpath / \"test_images_path.csv\"),\n",
        "    base_dir=str(dirpath),\n",
        "    # transform = transforms_resnet,\n",
        "    transform = transformations_resnet,\n",
        "    return_id=True\n",
        ")\n",
        "test_image_ids = test_dataset.df['id'].tolist()\n",
        "#Create dataloader\n",
        "test_loader = DataLoader(test_dataset, batch_size=val_batch_size, shuffle=False)\n",
        "\n",
        "# # 3. Check a batch from the DataLoader\n",
        "# batch_images, batch_labels = next(iter(test_loader))\n",
        "# print(f\"\\nBatch images shape: {batch_images.shape}\")  # Should be [32, 3, 224, 224]\n",
        "# print(f\"Batch images type: {type(batch_images)}\")     # Should be torch.Tensor\n",
        "# print(f\"Batch images dtype: {batch_images.dtype}\")    # Should be torch.float32\n",
        "# print(f\"Batch labels shape: {batch_labels.shape}\")    # Should be [32]\n",
        "# print(f\"Batch labels type: {type(batch_labels)}\")     # Should be torch.Tensor\n",
        "# print(f\"Batch labels dtype: {batch_labels.dtype}\")    # Could be torch.int64"
      ],
      "metadata": {
        "id": "uO8WdS_LtjId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "finetuned_model = models.resnet152()\n",
        "num_ftrs = finetuned_model.fc.in_features\n",
        "finetuned_model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "finetuned_model.load_state_dict(torch.load(\"/content/best_model.pth\"))\n",
        "finetuned_model.to(device)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N6sGXPTl6rRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run model\n",
        "test_ids, test_preds = predict(finetuned_model, test_loader, device=device)"
      ],
      "metadata": {
        "id": "HkkdiOTiw258"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate submission.csv\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": test_ids,\n",
        "    \"label\": test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission2.csv\", index=False)"
      ],
      "metadata": {
        "id": "gKXTisekx_PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EWHMPHAhzRcJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}