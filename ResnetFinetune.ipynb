{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/YasinKaryagdi/AppliedMLProject/blob/ResnetColab/ResnetFinetune.ipynb",
      "authorship_tag": "ABX9TyMwKdffPLMPBhE9oBpXHIU4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasinKaryagdi/AppliedMLProject/blob/ResnetColab/ResnetFinetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "jKm4ZAjDpgth",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#load files (run once when starting environment)\n",
        "# !git clone https://YasinKaryagdi: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@github.com/YasinKaryagdi/AppliedMLProject.git\n",
        "# !cp -r /content/drive/MyDrive/Machinelearning_files/augmented_set.zip /content/\n",
        "# !unzip augmented_set.zip\n",
        "# !cp -r /content/drive/MyDrive/Machinelearning_files/validate_split.csv /content/\n",
        "# !cp -r /content/drive/MyDrive/Machinelearning_files/train_augmented.csv /content/\n",
        "# !cp -r /content/drive/MyDrive/Machinelearning_files/train_split.csv /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually add augmented set+augmented csv for now + test set csv"
      ],
      "metadata": {
        "id": "fyE0D1e-NR5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from imutils import paths\n",
        "from pathlib import Path\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "Jpb3XBcdyvwr"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cwd = Path.cwd()\n",
        "gitpath = cwd / \"AppliedMLProject\"\n",
        "dirpath = gitpath / \"aml-2025-feathers-in-focus\"\n",
        "train_images_csv = dirpath / \"train_images.csv\"\n",
        "train_images_folder = dirpath / \"train_images\"\n",
        "image_classes = dirpath / \"class_names.npy\"\n",
        "drive_path = cwd / \"drive\" / \"MyDrive\" / \"Machinelearning files\"\n",
        "val_images_csv = cwd / \"validate_split.csv\"\n"
      ],
      "metadata": {
        "id": "NaI9baZX_ab5"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining model and training variables\n",
        "#use augmented trainingset\n",
        "use_augmented = True\n",
        "#model\n",
        "model_name = \"efficientnetb0\"\n",
        "#possible models: \"squeezenet\", \"resnet50\", \"resnet152\", \"efficientnetb0\"\n",
        "# \"efficiennetV2s\", \"SwinV2t\"\n",
        "#training batchsize\n",
        "train_batch_size = 64\n",
        "#validation & testing batchsize\n",
        "val_batch_size = 128\n",
        "#Epochs\n",
        "num_epochs = 15\n",
        "#feature extraction option (freeze)\n",
        "feature_extract = False\n",
        "#resize to:\n",
        "size = (256,256)\n",
        "#use pretrained or not\n",
        "use_pretrained = True\n",
        "classes = np.load(image_classes, allow_pickle=True).item()\n",
        "num_classes = len(classes)\n",
        "#train-test split\n",
        "split = 0.85\n",
        "#model save name\n",
        "model_save_name = (model_name + \"_\" +\n",
        "                   (\"freeze\" if feature_extract else \"nofreeze\") + \"_\" +\n",
        "                   (\"aug\" if use_augmented else \"noaug\")\n",
        "                   )\n",
        "model_save_name"
      ],
      "metadata": {
        "id": "_pU3X7eQ338C",
        "outputId": "93d2477e-6d7a-491c-c4bd-a17d92ab7d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'efficientnetb0_nofreeze_aug'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CSVDataset(Dataset):\n",
        "    def __init__(self, csv_file, base_dir, transform=None, return_id=False):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.base_dir = base_dir\n",
        "        self.transform = transform\n",
        "        self.return_id = return_id  # Useful for test set where no labels exist\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # extract fields\n",
        "        img_id = row['id'] if self.return_id else None\n",
        "        relative_path = row['image_path'].lstrip('/')  # safe\n",
        "        label = row['label'] - 1   # shift to 0-based indexing\n",
        "\n",
        "        # build full path\n",
        "        img_path = os.path.join(self.base_dir, relative_path)\n",
        "\n",
        "        # load\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # transform\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # optionally return id\n",
        "        if self.return_id:\n",
        "            return image, label, img_id\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "L3-GYuBXHV6Y"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "metadata": {
        "id": "UNhVRp2SZVX5"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,\n",
        "                train_loader,\n",
        "                val_loader,\n",
        "                criterion,\n",
        "                optimizer,\n",
        "                schedular=None,\n",
        "                num_epochs=10,\n",
        "                device=\"cuda\"):\n",
        "    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n",
        "    since = time.time()\n",
        "    model.to(device)\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    val_acc_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "        for phase in ['train', 'val']:\n",
        "              if phase == 'train':\n",
        "                  model.train()  # Set model to training mode\n",
        "              else:\n",
        "                  model.eval()   # Set model to evaluate mode\n",
        "\n",
        "              running_loss = 0.0\n",
        "              running_corrects = 0\n",
        "\n",
        "              # Iterate over data.\n",
        "              for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "                  inputs = inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "\n",
        "                  # zero the parameter gradients\n",
        "                  optimizer.zero_grad()\n",
        "\n",
        "                  # forward\n",
        "                  # track history if only in train\n",
        "                  with torch.set_grad_enabled(phase == 'train'):\n",
        "                      outputs = model(inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                      # backward + optimize only if in training phase\n",
        "                      if phase == 'train':\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "                  # statistics\n",
        "                  running_loss += loss.item() * inputs.size(0)\n",
        "                  running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "              epoch_loss = running_loss / len(dataloaders_dict[phase].dataset)\n",
        "              epoch_acc = running_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "              print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "              # deep copy the model\n",
        "              if phase == 'val' and epoch_acc > best_acc:\n",
        "                  best_acc = epoch_acc\n",
        "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "              if phase == 'val':\n",
        "                  val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n"
      ],
      "metadata": {
        "id": "YseV73jKZVN-"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define some standard transformations\n",
        "transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((size)),\n",
        "    transforms.Normalize(mean = (0.5,0.5,0.5), std = (0.5,0.5,0.5))\n",
        "    ])\n",
        "transformations_resnet = models.ResNet152_Weights.IMAGENET1K_V1.transforms()\n",
        "## Probably better to follow the original resnet transformations\n",
        "#See: (model.ResNet152_Weights.IMAGENET1K_V1.transforms)"
      ],
      "metadata": {
        "id": "8f7j0yqN9Upj"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.efficientnet import efficientnet_b0\n",
        "model_ft = None\n",
        "# Initialize model\n",
        "if model_name == \"resnet152\":\n",
        "  \"\"\"Resnet152\"\"\"\n",
        "  ResNet_Weights = models.ResNet152_Weights.DEFAULT\n",
        "  model_transforms = ResNet_Weights.transforms()\n",
        "  if use_pretrained:\n",
        "    model_ft = models.resnet152(weights=ResNet_Weights)\n",
        "  else:\n",
        "    model_ft = models.resnet152()\n",
        "  num_ftrs = model_ft.fc.in_features\n",
        "  model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "if model_name == \"resnet50\":\n",
        "  \"\"\"Resnet50\"\"\"\n",
        "  ResNet_Weights = models.ResNet50_Weights.DEFAULT\n",
        "  model_transforms = ResNet_Weights.transforms()\n",
        "  if use_pretrained:\n",
        "    model_ft = models.resnet50(weights=ResNet_Weights)\n",
        "  else:\n",
        "    model_ft = models.resnet50()\n",
        "  num_ftrs = model_ft.fc.in_features\n",
        "  model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "if model_name == \"squeezenet\":\n",
        "  \"\"\"Squeezenet\"\"\"\n",
        "  squeezenet1_0_weights = models.SqueezeNet1_0_Weights.DEFAULT\n",
        "  model_transforms = squeezenet1_0_weights.transforms()\n",
        "  if use_pretrained:\n",
        "    model_ft = models.squeezenet1_0(weights=squeezenet1_0_weights)\n",
        "  else:\n",
        "    model_ft = models.squeezenet1_0()\n",
        "  set_parameter_requires_grad(model_ft, feature_extract)\n",
        "  model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "  model_ft.num_classes = num_classes\n",
        "if model_name == \"efficientnetb0\":\n",
        "  \"\"\"Efficientnetb0\"\"\"\n",
        "  efficientnet_b0_weights = models.EfficientNet_B0_Weights.DEFAULT\n",
        "  model_transforms = efficientnet_b0_weights.transforms()\n",
        "  if use_pretrained:\n",
        "    model_ft = models.efficientnet_b0(weights=efficientnet_b0_weights)\n",
        "  else:\n",
        "    model_ft = models.efficientnet_b0()\n",
        "  set_parameter_requires_grad(model_ft, feature_extract)\n",
        "  num_ftrs = model_ft.classifier[1].in_features\n",
        "  model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
        "  model_ft.num_classes = num_classes\n",
        "if model_name == \"efficientnetV2s\":\n",
        "  \"\"\"EfficientnetV2s\"\"\"\n",
        "  efficientnet_v2_s_weights = models.EfficientNet_V2_S_Weights.DEFAULT\n",
        "  model_transforms = efficientnet_v2_s_weights.transforms()\n",
        "  if use_pretrained:\n",
        "    model_ft = models.efficientnet_v2_s(weights=efficientnet_v2_s_weights)\n",
        "  else:\n",
        "    model_ft = models.efficientnet_v2_s()\n",
        "  set_parameter_requires_grad(model_ft, feature_extract)\n",
        "  num_ftrs = model_ft.classifier[1].in_features\n",
        "  model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
        "  model_ft.num_classes = num_classes\n",
        "if model_name == \"SwinV2t\":\n",
        "  \"\"\"SwinV2t\"\"\"\n",
        "  swin_v2_t_weights = models.Swin_V2_T_Weights.DEFAULT\n",
        "  model_transforms = swin_v2_t_weights.transforms()\n",
        "  if use_pretrained:\n",
        "    model_ft = models.swin_v2_t(weights=swin_v2_t_weights)\n",
        "  else:\n",
        "    model_ft = models.swin_v2_t()\n",
        "  set_parameter_requires_grad(model_ft, feature_extract)\n",
        "  num_ftrs = model_ft.head.in_features\n",
        "  model_ft.head = nn.Linear(num_ftrs, num_classes)\n",
        "  model_ft.num_classes = num_classes\n"
      ],
      "metadata": {
        "id": "FqSjkmbPIWfS"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checker to find last layer\n",
        "\"\"\"Efficientnetb0\"\"\"\n",
        "# model = models.resnet50()\n",
        "# # for name, module in model.named_modules():\n",
        "# #     print(name, \":\", module)\n",
        "# printmodel = models.swin_v2_t()\n",
        "# for name, module in printmodel.named_modules():\n",
        "#     print(name, \":\", module)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cK8Zv52f9s0d",
        "outputId": "1d9bd31f-befe-45da-aabd-f97faeed740d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Efficientnetb0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if use_augmented == False:\n",
        "  full_dataset = CSVDataset(\n",
        "      csv_file=str(dirpath / \"train_images.csv\"),\n",
        "      base_dir=str(dirpath),\n",
        "      transform = model_transforms,\n",
        "      return_id=False\n",
        "  )\n",
        "  loader = DataLoader(full_dataset, batch_size=train_batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "l-tCV3MxO05B"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if use_augmented == True:\n",
        "  train_dataset = CSVDataset(\n",
        "      csv_file=str(cwd / \"train_augmented.csv\"),\n",
        "      base_dir=str(cwd),\n",
        "      transform = model_transforms,\n",
        "      return_id=False\n",
        "  )\n",
        "  val_dataset = CSVDataset(\n",
        "      csv_file=str(val_images_csv),\n",
        "      base_dir=str(dirpath),\n",
        "      transform = model_transforms,\n",
        "      return_id=False\n",
        "  )"
      ],
      "metadata": {
        "id": "nPhB2qnJRU8X"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-validation split\n",
        "# Split into train (85%) and validation (15%)\n",
        "if use_augmented == False:\n",
        "  train_size = int(split * len(full_dataset))\n",
        "  val_size = len(full_dataset) - train_size\n",
        "  train_dataset, val_dataset = random_split(\n",
        "      full_dataset,\n",
        "      [train_size, val_size],\n",
        "      generator=torch.Generator().manual_seed(8)\n",
        "  )"
      ],
      "metadata": {
        "id": "i4fYskKDSYsg"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loaders\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=train_batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=4,\n",
        "                          pin_memory=True,\n",
        "                          prefetch_factor=2,\n",
        "                          persistent_workers=True)\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=val_batch_size,\n",
        "                        shuffle=False,\n",
        "                        num_workers=4,\n",
        "                        pin_memory=True,\n",
        "                        prefetch_factor=2,\n",
        "                        persistent_workers=True\n",
        "                        )"
      ],
      "metadata": {
        "id": "2vCiR-hbVSTy",
        "outputId": "57894c47-1299-4fba-e63d-95db709085b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check if it does what I want it to\n",
        "# 1. Check dataset length\n",
        "print(f\"Dataset size: {len(train_dataset)}\")\n",
        "\n",
        "# 2. Get a single sample\n",
        "image, label = train_dataset[0]\n",
        "print(f\"Single image shape: {image.shape}\")  # Should be [3, 224, 224]\n",
        "print(f\"Single image type: {type(image)}\")   # Should be torch.Tensor\n",
        "print(f\"Single label: {label}\")              # Should be an integer\n",
        "print(f\"Label type: {type(label)}\")          # Should be int or numpy.int64\n",
        "\n",
        "# 3. Check a batch from the DataLoader\n",
        "batch_images, batch_labels = next(iter(train_loader))\n",
        "print(f\"\\nBatch images shape: {batch_images.shape}\")  # Should be [32, 3, 224, 224]\n",
        "print(f\"Batch images type: {type(batch_images)}\")     # Should be torch.Tensor\n",
        "print(f\"Batch images dtype: {batch_images.dtype}\")    # Should be torch.float32\n",
        "print(f\"Batch labels shape: {batch_labels.shape}\")    # Should be [32]\n",
        "print(f\"Batch labels type: {type(batch_labels)}\")     # Should be torch.Tensor\n",
        "print(f\"Batch labels dtype: {batch_labels.dtype}\")    # Could be torch.int64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwTdcbP7H8Xu",
        "outputId": "ef2f0d4e-d8f9-42e9-cf6c-ee9f9d7b7007"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 28260\n",
            "Single image shape: torch.Size([3, 224, 224])\n",
            "Single image type: <class 'torch.Tensor'>\n",
            "Single label: 41\n",
            "Label type: <class 'numpy.int64'>\n",
            "\n",
            "Batch images shape: torch.Size([64, 3, 224, 224])\n",
            "Batch images type: <class 'torch.Tensor'>\n",
            "Batch images dtype: torch.float32\n",
            "Batch labels shape: torch.Size([64])\n",
            "Batch labels type: <class 'torch.Tensor'>\n",
            "Batch labels dtype: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect if we have a GPU available\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DartSzDJXDPX",
        "outputId": "ffc25a08-2a20-464e-9fa6-4add86c07c72"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#put model on device\n",
        "model_ft = model_ft.to(device)"
      ],
      "metadata": {
        "id": "w-W26P52XRB_"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gather optimizable parameters\n",
        "params_to_update = model_ft.parameters()\n",
        "#Design optimzer\n",
        "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "# Setup the loss func\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "1pT9gfszYnX8"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate\n",
        "model_trained, hist = train_model(model_ft,\n",
        "                            train_loader,\n",
        "                            val_loader,\n",
        "                            criterion,\n",
        "                            optimizer,\n",
        "                            schedular=None,\n",
        "                            num_epochs=num_epochs,\n",
        "                            device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prs-oDveZHBb",
        "outputId": "eb886249-33a3-48b1-9372-7bdac38411f2"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:17<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 4.9958 Acc: 0.0943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:05<00:00,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 4.4590 Acc: 0.2519\n",
            "\n",
            "Epoch 2/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:17<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 3.8476 Acc: 0.3408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:05<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 3.1412 Acc: 0.4109\n",
            "\n",
            "Epoch 3/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:17<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 2.7396 Acc: 0.5011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:07<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 2.3282 Acc: 0.5165\n",
            "\n",
            "Epoch 4/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:16<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 2.0172 Acc: 0.6203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:05<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.8661 Acc: 0.5687\n",
            "\n",
            "Epoch 5/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:16<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.5365 Acc: 0.7121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.5662 Acc: 0.6145\n",
            "\n",
            "Epoch 6/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:18<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 1.1945 Acc: 0.7807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:06<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.3854 Acc: 0.6361\n",
            "\n",
            "Epoch 7/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:17<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.9422 Acc: 0.8374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.2540 Acc: 0.6730\n",
            "\n",
            "Epoch 8/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:17<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.7503 Acc: 0.8813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:07<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.1780 Acc: 0.6858\n",
            "\n",
            "Epoch 9/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:17<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5996 Acc: 0.9123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:07<00:00,  1.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.1175 Acc: 0.6883\n",
            "\n",
            "Epoch 10/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:17<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4896 Acc: 0.9327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:05<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.0807 Acc: 0.7010\n",
            "\n",
            "Epoch 11/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:17<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4088 Acc: 0.9476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:05<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.0657 Acc: 0.7036\n",
            "\n",
            "Epoch 12/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:17<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3403 Acc: 0.9592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:07<00:00,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.0537 Acc: 0.7074\n",
            "\n",
            "Epoch 13/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:18<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.2910 Acc: 0.9654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.0361 Acc: 0.7087\n",
            "\n",
            "Epoch 14/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:16<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.2471 Acc: 0.9729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.0230 Acc: 0.7125\n",
            "\n",
            "Epoch 15/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 442/442 [02:17<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.2160 Acc: 0.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:06<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 1.0264 Acc: 0.7087\n",
            "\n",
            "Training complete in 35m 57s\n",
            "Best val Acc: 0.712468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_trained.state_dict(), f\"{model_save_name}.pth\")"
      ],
      "metadata": {
        "id": "sU_IyDNmtbKh"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{model_save_name}_results.txt', 'w') as f:\n",
        "    for line in hist:\n",
        "        f.write(f\"{line}\\n\")"
      ],
      "metadata": {
        "id": "1y-0V1dF9C5Z"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict(model, test_loader, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    preds_list = []\n",
        "    ids_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, img_ids in tqdm(test_loader):\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            #Readd 1 to label to give right predictions\n",
        "            preds_list.extend(preds.cpu().numpy()+1)\n",
        "            ids_list.extend(img_ids.numpy())\n",
        "\n",
        "    return ids_list, preds_list"
      ],
      "metadata": {
        "id": "zusGMHLAuFWG"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Test set\n",
        "test_dataset = CSVDataset(\n",
        "    csv_file=str(dirpath / \"test_images_path.csv\"),\n",
        "    base_dir=str(dirpath),\n",
        "    transform = model_transforms,\n",
        "    return_id=True\n",
        ")\n",
        "test_image_ids = test_dataset.df['id'].tolist()\n",
        "#Create dataloader\n",
        "test_loader = DataLoader(test_dataset, batch_size=val_batch_size, shuffle=False)\n",
        "\n",
        "# # 3. Check a batch from the DataLoader\n",
        "# batch_images, batch_labels = next(iter(test_loader))\n",
        "# print(f\"\\nBatch images shape: {batch_images.shape}\")  # Should be [32, 3, 224, 224]\n",
        "# print(f\"Batch images type: {type(batch_images)}\")     # Should be torch.Tensor\n",
        "# print(f\"Batch images dtype: {batch_images.dtype}\")    # Should be torch.float32\n",
        "# print(f\"Batch labels shape: {batch_labels.shape}\")    # Should be [32]\n",
        "# print(f\"Batch labels type: {type(batch_labels)}\")     # Should be torch.Tensor\n",
        "# print(f\"Batch labels dtype: {batch_labels.dtype}\")    # Could be torch.int64"
      ],
      "metadata": {
        "id": "uO8WdS_LtjId"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "finetuned_model = models.resnet152()\n",
        "num_ftrs = finetuned_model.fc.in_features\n",
        "finetuned_model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "finetuned_model.load_state_dict(torch.load(\"/content/best_model.pth\"))\n",
        "finetuned_model.to(device)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N6sGXPTl6rRt",
        "outputId": "f8378b4a-3f73-412a-f3ec-f367741be726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/best_model.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2766496221.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetuned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfinetuned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfinetuned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/best_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfinetuned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/best_model.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run model\n",
        "test_ids, test_preds = predict(finetuned_model, test_loader, device=device)"
      ],
      "metadata": {
        "id": "HkkdiOTiw258"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate submission.csv\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": test_ids,\n",
        "    \"label\": test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission2.csv\", index=False)"
      ],
      "metadata": {
        "id": "gKXTisekx_PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hist)"
      ],
      "metadata": {
        "id": "EWHMPHAhzRcJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}