{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14uTdaRO2ml5SDkezfexGzXpkTWDGmGKf","timestamp":1765706078066}],"gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import time\n","import copy\n","from tqdm import tqdm\n","from pathlib import Path\n","import pickle\n","import random\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from PIL import Image\n","import torch\n","from torchsummary import summary\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.amp import autocast, GradScaler\n","\n","import torchvision\n","from torchvision import datasets, models, transforms\n","\n","from torch.utils.data import Dataset, DataLoader, random_split"],"metadata":{"id":"Jpb3XBcdyvwr","executionInfo":{"status":"ok","timestamp":1765719516480,"user_tz":-60,"elapsed":7,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","execution_count":114,"metadata":{"collapsed":true,"id":"MjU1TVzrkzfb","executionInfo":{"status":"ok","timestamp":1765719516498,"user_tz":-60,"elapsed":3,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"outputs":[],"source":["# #load files\n","if not os.path.exists(\"/content/drive\"):\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","if not os.path.exists(\"/content/AppliedMLProject\"):\n","  !git clone https://YasinKaryagdi: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@github.com/YasinKaryagdi/AppliedMLProject.git\n","if not os.path.exists(\"/content/augmented_set.zip\"):\n","  !cp -r /content/drive/MyDrive/Machinelearning_files/augmented_set.zip /content/\n","  !unzip augmented_set.zip\n","if not os.path.exists(\"/content/validate_split.csv\"):\n","  !cp -r /content/drive/MyDrive/Machinelearning_files/validate_split.csv /content/\n","  !cp -r /content/drive/MyDrive/Machinelearning_files/train_augmented.csv /content/\n","  !cp -r /content/drive/MyDrive/Machinelearning_files/train_split.csv /content/\n","  !cp -r /content/drive/MyDrive/Machinelearning_files/train_balanced.csv /content/"]},{"cell_type":"code","source":["cwd = Path.cwd()\n","gitpath = cwd / \"AppliedMLProject\"\n","dirpath = gitpath / \"aml-2025-feathers-in-focus\"\n","train_images_csv = dirpath / \"train_images.csv\"\n","train_images_folder = dirpath / \"train_images\"\n","image_classes = dirpath / \"class_names.npy\"\n","drive_path = cwd / \"drive\" / \"MyDrive\" / \"Machinelearning files\"\n","val_images_csv = cwd / \"validate_split.csv\"\n","train_balanced_csv = cwd / \"train_balanced.csv\"\n"],"metadata":{"id":"NaI9baZX_ab5","executionInfo":{"status":"ok","timestamp":1765719516522,"user_tz":-60,"elapsed":23,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["#Defining model and training variables\n","#use augmented trainingset and if so, use balanced set?\n","use_augmented = True\n","if use_augmented:\n","  use_balanced = True\n","  augmentations = []\n","#model\n","model_name = \"MODERNRES\" # <- modelname goes here\n","#possible models: \"M3MAX\", \"SIMPLE1\", \"CLASSIC1\", \"CLASSICRES\", \"MODERNRES\"\n","#use model transformations or standard\n","use_model_transforms = False\n","#use_scaler\n","use_scaler = True\n","#earlystop\n","early_stopping = False\n","patience = 10\n","min_delta = 0\n","#training batchsize\n","train_batch_size = 64\n","#validation & testing batchsize\n","val_batch_size = 64\n","#Epochs\n","num_epochs = 30\n","#Optimizer build:\n","#learningrate\n","learning_rate = 0.001\n","#momentum\n","moment = 0.9\n","#weight decay\n","wd = 0.001\n","#resize to:\n","size = (256,256)\n","#use pretrained or not\n","use_pretrained = True\n","classes = np.load(image_classes, allow_pickle=True).item()\n","num_classes = len(classes)\n","#train-test split\n","split = 0.85\n","#model save name\n","model_save_name = (model_name + \"_\" +\n","                   (\"_aug\" if use_augmented else \"noaug\")+\n","                   (\"_bal\" if use_balanced else \"\")\n","                   )\n","model_save_name\n","#use seed?\n","use_seed = True\n","seed = 42\n","SEEDS = [3,4,5,6,7,8,9]"],"metadata":{"id":"3iFQhoqNq7DK","executionInfo":{"status":"ok","timestamp":1765719516541,"user_tz":-60,"elapsed":18,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":["Test model classes go here"],"metadata":{"id":"OwrangrexR6g"}},{"cell_type":"code","source":["class ModelM3MAX(nn.Module):\n","    def __init__(self):\n","        super(ModelM3MAX, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1, stride = 1, bias=False)\n","        self.conv1_bn = nn.BatchNorm2d(32)\n","\n","        self.conv2 = nn.Conv2d(32, 48, 3, padding=1, bias=False)\n","        self.conv2_bn = nn.BatchNorm2d(48)\n","\n","        self.conv3 = nn.Conv2d(48, 64, 3, padding=1, bias=False)\n","        self.conv3_bn = nn.BatchNorm2d(64)\n","\n","        self.conv4 = nn.Conv2d(64, 80, 3, padding=1, bias=False)\n","        self.conv4_bn = nn.BatchNorm2d(80)\n","\n","        self.conv5 = nn.Conv2d(80, 96, 3, padding=1, bias=False)\n","        self.conv5_bn = nn.BatchNorm2d(96)\n","\n","        self.conv6 = nn.Conv2d(96, 112, 3, padding=1, bias=False)\n","        self.conv6_bn = nn.BatchNorm2d(112)\n","\n","        self.conv7 = nn.Conv2d(112, 128, 3, padding=1, bias=False)\n","        self.conv7_bn = nn.BatchNorm2d(128)\n","\n","        self.conv8 = nn.Conv2d(128, 144, 3, padding=1, bias=False)\n","        self.conv8_bn = nn.BatchNorm2d(144)\n","\n","        self.conv9 = nn.Conv2d(144, 160, 3, padding=1, bias=False)\n","        self.conv9_bn = nn.BatchNorm2d(160)\n","\n","        self.conv10 = nn.Conv2d(160, 176, 3, padding=1, bias=False)\n","        self.conv10_bn = nn.BatchNorm2d(176)\n","\n","        # unchanged: 176 * 8 * 8 = 11264\n","        self.fc1 = nn.Linear(11264, 200, bias=False)\n","        self.fc1_bn = nn.BatchNorm1d(200)\n","\n","    def get_logits(self, x):\n","        x = (x - 0.5) * 2.0\n","\n","        conv1 = F.relu(self.conv1_bn(self.conv1(x)))\n","        conv2 = F.relu(self.conv2_bn(self.conv2(conv1)))\n","        conv2 = F.max_pool2d(conv2, 2)  # 256 -> 128\n","\n","        conv3 = F.relu(self.conv3_bn(self.conv3(conv2)))\n","        conv4 = F.relu(self.conv4_bn(self.conv4(conv3)))\n","        conv4 = F.max_pool2d(conv4, 2)  # 128 -> 64\n","\n","        conv5 = F.relu(self.conv5_bn(self.conv5(conv4)))\n","        conv6 = F.relu(self.conv6_bn(self.conv6(conv5)))\n","        conv6 = F.max_pool2d(conv6, 2)  # 64 -> 32\n","\n","        conv7 = F.relu(self.conv7_bn(self.conv7(conv6)))\n","        conv8 = F.relu(self.conv8_bn(self.conv8(conv7)))\n","        conv8 = F.max_pool2d(conv8, 2)  # 32 -> 16\n","\n","        conv9 = F.relu(self.conv9_bn(self.conv9(conv8)))\n","        conv10 = F.relu(self.conv10_bn(self.conv10(conv9)))\n","        conv10 = F.max_pool2d(conv10, 2)  # 16 -> 8\n","\n","        # Now conv10 is (batch, 176, 8, 8)\n","        flat = torch.flatten(conv10.permute(0, 2, 3, 1), 1)\n","        logits = self.fc1_bn(self.fc1(flat))\n","        return logits\n","\n","    def forward(self, x):\n","        logits = self.get_logits(x)\n","        return logits"],"metadata":{"id":"NGj2LBX6IvdQ","executionInfo":{"status":"ok","timestamp":1765719516576,"user_tz":-60,"elapsed":29,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":117,"outputs":[]},{"cell_type":"code","source":["class SIMPLE1(nn.Module):\n","    def __init__(self):\n","        super(SIMPLE1, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1, stride = 1, bias=False)\n","        self.conv1_bn = nn.BatchNorm2d(32)\n","\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1, bias=False)\n","        self.conv2_bn = nn.BatchNorm2d(64)\n","\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1, bias=False)\n","        self.conv3_bn = nn.BatchNorm2d(128)\n","\n","        self.conv4 = nn.Conv2d(128, 164, 3, padding=1, bias=False)\n","        self.conv4_bn = nn.BatchNorm2d(164)\n","\n","        self.conv5 = nn.Conv2d(164, 176, 3, padding=1, bias=False)\n","        self.conv5_bn = nn.BatchNorm2d(176)\n","\n","        # unchanged: 176 * 8 * 8 = 11264\n","        self.fc1 = nn.Linear(11264, 200, bias=False)\n","        self.fc1_bn = nn.BatchNorm1d(200)\n","\n","    def get_logits(self, x):\n","        x = (x - 0.5) * 2.0\n","\n","        #conv 1\n","        x = F.relu(self.conv1_bn(self.conv1(x)))\n","        x = F.max_pool2d(x, 2) #256 -> 128\n","\n","        #conv 2\n","        x = F.relu(self.conv2_bn(self.conv2(x)))\n","        x = F.max_pool2d(x, 2) #128 -> 64\n","\n","        #conv 3\n","        x = F.relu(self.conv3_bn(self.conv3(x)))\n","        x = F.max_pool2d(x, 2) #64 -> 32\n","\n","        # Conv 4\n","        x = F.relu(self.conv4_bn(self.conv4(x)))\n","        x = F.max_pool2d(x, 2)   # 32 -> 16\n","\n","        # Conv 5\n","        x = F.relu(self.conv5_bn(self.conv5(x)))\n","        x = F.max_pool2d(x, 2)   # 16 -> 8\n","\n","        # x is now (batch, 176, 8, 8)\n","        x = torch.flatten(x, 1)  # (batch, 11264)\n","\n","        logits = self.fc1_bn(self.fc1(x))\n","        return logits\n","\n","    def forward(self, x):\n","        logits = self.get_logits(x)\n","        return logits"],"metadata":{"id":"5gYnd_OVQ4oi","executionInfo":{"status":"ok","timestamp":1765719516580,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":118,"outputs":[]},{"cell_type":"code","source":["class CLASSIC1(nn.Module):\n","    def __init__(self):\n","        super(CLASSIC1, self).__init__()\n","\n","        # 5 stages with double conv + pooling\n","        self.stage1 = self.conv_block(3, 32)\n","        self.stage2 = self.conv_block(32, 64)\n","        self.stage3 = self.conv_block(64, 128)\n","        self.stage4 = self.conv_block(128, 256) #adapt to 256 and 512 to conform to memory norms (powers of 2)\n","        self.stage5 = self.conv_block(256, 512)\n","\n","        self.gap = nn.AdaptiveAvgPool2d(1)   # Global Average Pooling reduces parameters and betters generalization\n","        self.dropout = nn.Dropout(p=0.4) # Prevents overfitting, with some reduced probability to allow quicker learning and not over-regularize\n","        self.fc1 = nn.Linear(512, 200)\n","\n","    @staticmethod\n","    def conv_block(in_ch, out_ch): #first building block for conv layers (stack of 2)\n","        # Standard pattern: Conv -> BN -> ReLU -> Conv -> BN -> ReLU -> MaxPool\n","        return nn.Sequential(\n","            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","\n","            nn.MaxPool2d(2)\n","        )\n","\n","    def forward(self, x): #replaced forward + logit with just forward\n","        x = (x - 0.5) * 2.0\n","\n","        x = self.stage1(x)\n","        x = self.stage2(x)\n","        x = self.stage3(x)\n","        x = self.stage4(x)\n","        x = self.stage5(x)\n","        # x is now (Batch_Size, 512, 1, 1) assuming input was 32x32 (5 max pools)\n","\n","        x = self.gap(x)\n","        x = torch.flatten(x, 1)\n","        x = self.dropout(x)\n","        logits = self.fc1(x)\n","        return logits"],"metadata":{"id":"Ffru77W9PMUy","executionInfo":{"status":"ok","timestamp":1765719516592,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":119,"outputs":[]},{"cell_type":"code","source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_ch, out_ch):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_ch)\n","        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_ch)\n","\n","        # shortcut: identity if channels match, otherwise 1x1 conv\n","        self.shortcut = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.pool = nn.MaxPool2d(2)\n","\n","    def forward(self, x):\n","        identity = self.shortcut(x)\n","        out = self.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += identity\n","        out = self.relu(out)\n","        out = self.pool(out)\n","        return out\n","\n","class CLASSICRES(nn.Module):\n","    def __init__(self, num_classes=200):\n","        super().__init__()\n","\n","        # Stage-level residual blocks\n","        self.stage1 = ResidualBlock(3, 32)       # 256 -> 128\n","        self.stage2 = ResidualBlock(32, 64)      # 128 -> 64\n","        self.stage3 = ResidualBlock(64, 128)     # 64 -> 32\n","        self.stage4 = ResidualBlock(128, 256)    # 32 -> 16\n","        self.stage5 = ResidualBlock(256, 512)    # 16 -> 8\n","\n","        # Classifier\n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","        self.dropout = nn.Dropout(p=0.4)\n","        self.fc = nn.Linear(512, num_classes)\n","\n","    def forward(self, x):\n","        x = (x - 0.5) * 2.0  # normalize to [-1, 1]\n","\n","        x = self.stage1(x)\n","        x = self.stage2(x)\n","        x = self.stage3(x)\n","        x = self.stage4(x)\n","        x = self.stage5(x)\n","\n","        x = self.gap(x)                  # (B, 512, 1, 1)\n","        x = torch.flatten(x, 1)          # (B, 512)\n","        x = self.dropout(x)\n","        logits = self.fc(x)\n","        return logits"],"metadata":{"id":"OvLIruF1le9l","executionInfo":{"status":"ok","timestamp":1765719516606,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["class SEBlock(nn.Module):\n","    def __init__(self, channels, reduction=16):\n","        super().__init__()\n","        self.fc1 = nn.Linear(channels, channels // reduction)\n","        self.fc2 = nn.Linear(channels // reduction, channels)\n","        self.activation = nn.ReLU()  # <- changed back from SiLU\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        b, c, h, w = x.size()\n","        # Squeeze: global average pooling\n","        y = x.mean(dim=(2, 3))           # (B, C)\n","        # Excitation: MLP\n","        y = self.fc2(self.activation(self.fc1(y)))  # (B, C)\n","        y = self.sigmoid(y).view(b, c, 1, 1)\n","        # Scale: multiply original feature map\n","        return x * y\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_ch, out_ch, use_se=False):\n","        super().__init__()\n","        self.use_se = use_se\n","\n","        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_ch)\n","        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_ch)\n","\n","        self.shortcut = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n","        self.act = nn.ReLU(inplace=True)  # <- changed back from SiLU\n","        self.pool = nn.MaxPool2d(2)\n","\n","        if use_se:\n","            self.se = SEBlock(out_ch)\n","\n","    def forward(self, x):\n","        identity = self.shortcut(x)\n","        out = self.act(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += identity\n","\n","        if self.use_se:\n","            out = self.se(out)\n","\n","        out = self.act(out)\n","        out = self.pool(out)\n","        return out\n","\n","\n","class MODERNRES(nn.Module):\n","    def __init__(self, num_classes=200):\n","        super().__init__()\n","\n","        # Stage-level residual blocks\n","        self.stage1 = ResidualBlock(3, 32, use_se=True)\n","        self.stage2 = ResidualBlock(32, 64, use_se=True)\n","        self.stage3 = ResidualBlock(64, 96, use_se=True)\n","        self.stage4 = ResidualBlock(96, 128, use_se=True)\n","        self.stage5 = ResidualBlock(128, 160, use_se=True)\n","\n","        # Classifier\n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","        self.dropout = nn.Dropout(p=0.4)\n","        self.fc = nn.Linear(160, num_classes)\n","\n","    def forward(self, x):\n","        x = (x - 0.5) * 2.0  # normalize to [-1, 1]\n","\n","        x = self.stage1(x)\n","        x = self.stage2(x)\n","        x = self.stage3(x)\n","        x = self.stage4(x)\n","        x = self.stage5(x)\n","\n","        x = self.gap(x)\n","        x = torch.flatten(x, 1)\n","        x = self.dropout(x)\n","        logits = self.fc(x)\n","        return logits"],"metadata":{"id":"L3m6_zuw7A97","executionInfo":{"status":"ok","timestamp":1765719516623,"user_tz":-60,"elapsed":3,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["class EnsembleModel(nn.Module):\n","    def __init__(self, modelList):\n","        super().__init__()\n","        self.models = nn.ModuleList(modelList)\n","        self.classifier = nn.Linear(200 * len(modelList), 200)\n","        self.dropout = nn.Dropout(p=0.5)\n","\n","    def forward(self, x):\n","        outputs = []\n","        for model in self.models:\n","            outputs.append(model(x))\n","\n","        x_cat = torch.cat(outputs, dim=1)\n","        x_cat = self.dropout(x_cat)\n","        out = self.classifier(x_cat)\n","        return out"],"metadata":{"id":"6kRYjcn6dVmw","executionInfo":{"status":"ok","timestamp":1765719516653,"user_tz":-60,"elapsed":16,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":122,"outputs":[]},{"cell_type":"markdown","source":["Test model activations go here"],"metadata":{"id":"m0PlFtpqr4rc"}},{"cell_type":"code","source":["# define test model+transforms here\n","if model_name == \"M3MAX\":\n","  custom_model = ModelM3MAX()\n","#gets 12.99 percent with: balanced augdata, lr 0.001, moment 0.9, wd 0.001, batchsize 32, epochs 15,\n","if model_name == \"SIMP1\":\n","  custom_model = SIMPLE1()\n","#gets 12.7 percent with: balanced augdata, lr 0.001, moment 0.9, wd 0.001, batchsize 32, epochs 15 (but fewer params, not much though)\n","if model_name == \"CLASSIC1\":\n","  custom_model = CLASSIC1()\n","#gets 15.6 percent with: balanced augdata, lr 0.001, moment 0.9, wd 0.001, batchsize 32, epochs 15 (but fewer params, not much though)\n","#but has quite some more potential with more epochs/higher learning rate/higher batch size\n","if model_name == \"CLASSICRES\":\n","  custom_model = CLASSICRES()\n","#gets 23 percent with: balanced augdata, lr 0.001, moment 0.9, wd 0.001, batchsize 64, epochs 15 (but fewer params, not much though)\n","if model_name == \"MODERNRES\":\n","  custom_model = MODERNRES()\n"],"metadata":{"id":"oVLnoxRIq27W","executionInfo":{"status":"ok","timestamp":1765719516676,"user_tz":-60,"elapsed":21,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":["Class and function definitions goes here"],"metadata":{"id":"D_st-PCKrxwN"}},{"cell_type":"code","source":["#remove randomness for benchmarking\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","if use_seed:\n","  set_seed(seed)"],"metadata":{"id":"xIVdMKzwuzMY","executionInfo":{"status":"ok","timestamp":1765719516679,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["#defining dataclass\n","class CSVDataset(Dataset):\n","    def __init__(self,\n","                 csv_file,\n","                 base_dir,\n","                 transform=None,\n","                 return_id=False,\n","                 augmentation_tags=None): # Added augmentation_tags parameter\n","        self.df = pd.read_csv(csv_file)\n","\n","        # Apply augmentation filtering if tags are provided\n","        if augmentation_tags is not None:\n","            # Ensure 'original' is always included\n","            all_tags_to_include = list(set(augmentation_tags + ['original']))\n","\n","            mask = pd.Series([False] * len(self.df), index=self.df.index)\n","            for tag in all_tags_to_include:\n","                # Check if the image_path contains the augmentation tag\n","                mask = mask | self.df['image_path'].str.contains(f'_{tag}.jpg', regex=False)\n","            self.df = self.df[mask].copy()\n","\n","        self.base_dir = base_dir\n","        self.transform = transform\n","        self.return_id = return_id\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","\n","        # extract fields\n","        img_id = row['id'] if self.return_id else None\n","        relative_path = row['image_path'].lstrip('/')  # safe\n","        label = row['label'] - 1   # shift to 0-based indexing\n","\n","        # build full path\n","        img_path = os.path.join(self.base_dir, relative_path)\n","\n","        # load\n","        image = Image.open(img_path).convert('RGB')\n","\n","        # transform\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        # optionally return id\n","        if self.return_id:\n","            return image, label, img_id\n","\n","        return image, label"],"metadata":{"id":"L3-GYuBXHV6Y","executionInfo":{"status":"ok","timestamp":1765719516707,"user_tz":-60,"elapsed":3,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":125,"outputs":[]},{"cell_type":"code","source":["def train_model(model,\n","                train_loader,\n","                val_loader,\n","                criterion,\n","                optimizer,\n","                schedular=None,\n","                num_epochs=10,\n","                early_stopping=False,\n","                epochs_no_improve=0,\n","                patience=5,\n","                min_delta=0.0,\n","                device=\"cuda\"):\n","\n","    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n","    since = time.time()\n","    model.to(device)\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    # Initialize history dictionary\n","    hist = {\n","        \"train_loss\": [],\n","        \"val_loss\": [],\n","        \"train_acc\": [],\n","        \"val_acc\": []\n","    }\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in tqdm(dataloaders_dict[phase]):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders_dict[phase].dataset)\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            # Save metrics in history\n","            if phase == 'train':\n","                hist['train_loss'].append(epoch_loss)\n","                hist['train_acc'].append(epoch_acc.item())\n","            else:\n","                hist['val_loss'].append(epoch_loss)\n","                hist['val_acc'].append(epoch_acc.item())\n","\n","                # Early stopping logic\n","                if epoch_acc > best_acc + min_delta:\n","                    print(f\"Validation improved ({best_acc:.4f} → {epoch_acc:.4f})\")\n","                    best_acc = epoch_acc\n","                    best_model_wts = copy.deepcopy(model.state_dict())\n","                    epochs_no_improve = 0\n","                else:\n","                    epochs_no_improve += 1\n","                    print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n","\n","        if epochs_no_improve >= patience and early_stopping:\n","            print(f\"Early stopping triggered at epoch {epoch+1}!\")\n","            break\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val Acc: {best_acc:.4f}')\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, hist"],"metadata":{"id":"YseV73jKZVN-","executionInfo":{"status":"ok","timestamp":1765719516741,"user_tz":-60,"elapsed":21,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":126,"outputs":[]},{"cell_type":"code","source":["def train_model(model,\n","                train_loader,\n","                val_loader,\n","                criterion,\n","                optimizer,\n","                schedular=None,\n","                num_epochs=10,\n","                early_stopping=False,\n","                epochs_no_improve=0,\n","                patience=5,\n","                min_delta=0.0,\n","                device=\"cuda\"):\n","\n","    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n","    since = time.time()\n","    model.to(device)\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    if use_scaler:\n","      scaler = GradScaler()\n","\n","    # Initialize history dictionary\n","    hist = {\n","        \"train_loss\": [],\n","        \"val_loss\": [],\n","        \"train_acc\": [],\n","        \"val_acc\": []\n","    }\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch+1}/{num_epochs}')\n","        print('-' * 10)\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            for inputs, labels in tqdm(dataloaders_dict[phase]):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                if use_scaler:\n","                  with torch.set_grad_enabled(phase == 'train'):\n","                    with autocast(\"cuda\"):  # Mixed precision context\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","                        _, preds = torch.max(outputs, 1)\n","\n","                    if phase == 'train':\n","                        scaler.scale(loss).backward()\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                else:\n","                  with torch.set_grad_enabled(phase == 'train'):\n","                      outputs = model(inputs)\n","                      loss = criterion(outputs, labels)\n","\n","                      _, preds = torch.max(outputs, 1)\n","\n","                      if phase == 'train':\n","                          loss.backward()\n","                          optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders_dict[phase].dataset)\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            # Save metrics in history\n","            if phase == 'train':\n","                hist['train_loss'].append(epoch_loss)\n","                hist['train_acc'].append(epoch_acc.item())\n","            else:\n","                hist['val_loss'].append(epoch_loss)\n","                hist['val_acc'].append(epoch_acc.item())\n","\n","                # Early stopping logic\n","                if epoch_acc > best_acc + min_delta:\n","                    print(f\"Validation improved ({best_acc:.4f} → {epoch_acc:.4f})\")\n","                    best_acc = epoch_acc\n","                    best_model_wts = copy.deepcopy(model.state_dict())\n","                    epochs_no_improve = 0\n","                else:\n","                    epochs_no_improve += 1\n","                    print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n","\n","        if epochs_no_improve >= patience and early_stopping:\n","            print(f\"Early stopping triggered at epoch {epoch+1}!\")\n","            break\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val Acc: {best_acc:.4f}')\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, hist"],"metadata":{"executionInfo":{"status":"ok","timestamp":1765719516745,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}},"id":"rGyenlEr6IZ8"},"execution_count":127,"outputs":[]},{"cell_type":"markdown","source":["Most basic transformations, standardizes rgb values, resizes images to set values and converts image to tensor"],"metadata":{"id":"KF7wg35Gs5f-"}},{"cell_type":"code","source":["#Define some standard transformations\n","transformations = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((size)),\n","    transforms.Normalize(mean = (0.5,0.5,0.5), std = (0.5,0.5,0.5))\n","    ])\n","## Probably better to follow the original resnet transformations\n","#See: (model.ResNet152_Weights.IMAGENET1K_V1.transforms)\n","if not use_model_transforms:\n","  model_transforms = transformations\n"],"metadata":{"id":"UzN_AvXNswB3","executionInfo":{"status":"ok","timestamp":1765719516772,"user_tz":-60,"elapsed":18,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":128,"outputs":[]},{"cell_type":"markdown","source":["Define datasets based on augmented or not"],"metadata":{"id":"DsCmG6nYtyrW"}},{"cell_type":"code","source":["if use_augmented == False:\n","  full_dataset = CSVDataset(\n","      csv_file=str(dirpath / \"train_images.csv\"),\n","      base_dir=str(dirpath),\n","      transform = model_transforms,\n","      return_id=False\n","  )\n","  train_size = int(split * len(full_dataset))\n","  val_size = len(full_dataset) - train_size\n","  train_dataset, val_dataset = random_split(\n","      full_dataset,\n","      [train_size, val_size],\n","      generator=torch.Generator().manual_seed(seed)\n","  )\n","  loader = DataLoader(full_dataset, batch_size=train_batch_size, shuffle=True)"],"metadata":{"id":"vLezHkjGs4Zk","executionInfo":{"status":"ok","timestamp":1765719516789,"user_tz":-60,"elapsed":15,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":129,"outputs":[]},{"cell_type":"code","source":["if use_augmented == True:\n","  if use_balanced:\n","    train_dataset = CSVDataset(\n","        csv_file=str(cwd / \"train_balanced.csv\"),\n","        base_dir=str(cwd),\n","        transform = model_transforms,\n","        return_id=False\n","    )\n","  else:\n","    train_dataset = CSVDataset(\n","        csv_file=str(cwd / \"train_augmented.csv\"),\n","        base_dir=str(cwd),\n","        transform = model_transforms,\n","        return_id=False\n","    )\n","  val_dataset = CSVDataset(\n","      csv_file=str(val_images_csv),\n","      base_dir=str(dirpath),\n","      transform = model_transforms,\n","      return_id=False\n","  )"],"metadata":{"id":"N5gGA7XZtxyP","executionInfo":{"status":"ok","timestamp":1765719516822,"user_tz":-60,"elapsed":32,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":130,"outputs":[]},{"cell_type":"code","source":["#define dataloaders\n","# data loaders\n","#create full loader\n","train_loader = DataLoader(train_dataset,\n","                          batch_size=train_batch_size,\n","                          shuffle=True,\n","                          num_workers=2,\n","                          pin_memory=True,\n","                          prefetch_factor=2,\n","                          persistent_workers=True)\n","val_loader = DataLoader(val_dataset,\n","                        batch_size=val_batch_size,\n","                        shuffle=False,\n","                        num_workers=2,\n","                        pin_memory=True,\n","                        prefetch_factor=2,\n","                        persistent_workers=True\n","                        )"],"metadata":{"id":"aCKiE6mhDpgV","executionInfo":{"status":"ok","timestamp":1765719516849,"user_tz":-60,"elapsed":43,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":131,"outputs":[]},{"cell_type":"code","source":["# Detect if we have a GPU available\n","torch.cuda.empty_cache()\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"id":"xFa_mDfNv8JS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765719516859,"user_tz":-60,"elapsed":12,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}},"outputId":"8daf5662-389d-4629-b121-f75893b835fc"},"execution_count":132,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":132}]},{"cell_type":"code","source":["#gather optimizable parameters\n","params_to_update = custom_model.parameters()\n","#Design optimzer\n","# optimizer = optim.SGD(params_to_update, lr=learning_rate, momentum=moment,\n","#                       weight_decay=wd\n","#                       )\n","optimizer = optim.AdamW(params_to_update, lr=learning_rate)\n","# Setup the loss func\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"uv1NVePuv8uU","executionInfo":{"status":"ok","timestamp":1765719516903,"user_tz":-60,"elapsed":43,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["#Get models:\n","import re\n","\n","model_dir = \"/content/drive/MyDrive/Test/\"\n","\n","# Ensure the directory exists to avoid FileNotFoundError during os.listdir\n","os.makedirs(model_dir, exist_ok=True)\n","\n","# Initialize a list to store the details of each model file\n","model_files_data = []\n","\n","model_pattern = re.compile(rf\"^{model_name}_(\\d+)\\.pth$\")\n","\n","print(f\"Scanning directory: {model_dir} for files matching pattern: {model_name}_<seed>.pth\")\n","\n","# Iterate through all files in the specified directory\n","for filename in os.listdir(model_dir):\n","    # Check if the file is a .pth file and matches the expected pattern\n","    match = model_pattern.match(filename)\n","    if match:\n","        seed = match.group(1)\n","        full_path = os.path.join(model_dir, filename)\n","        model_files_data.append({\n","            \"model_name\": model_name, # Using the global model_name variable as per instruction\n","            \"seed\": seed,\n","            \"path\": full_path\n","        })\n","\n","# Print the list of extracted model details\n","if model_files_data:\n","    print(\"Found model files:\")\n","    for model_info in model_files_data:\n","        print(model_info)\n","else:\n","    print(\"No model files found matching the pattern in the specified directory.\")"],"metadata":{"id":"0FDCI7_dThdv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765719516910,"user_tz":-60,"elapsed":33,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}},"outputId":"9d857efb-6611-4830-9c91-ba1b4158eacf"},"execution_count":134,"outputs":[{"output_type":"stream","name":"stdout","text":["Scanning directory: /content/drive/MyDrive/Test/ for files matching pattern: MODERNRES_<seed>.pth\n","Found model files:\n","{'model_name': 'MODERNRES', 'seed': '0', 'path': '/content/drive/MyDrive/Test/MODERNRES_0.pth'}\n","{'model_name': 'MODERNRES', 'seed': '1', 'path': '/content/drive/MyDrive/Test/MODERNRES_1.pth'}\n","{'model_name': 'MODERNRES', 'seed': '2', 'path': '/content/drive/MyDrive/Test/MODERNRES_2.pth'}\n","{'model_name': 'MODERNRES', 'seed': '3', 'path': '/content/drive/MyDrive/Test/MODERNRES_3.pth'}\n","{'model_name': 'MODERNRES', 'seed': '4', 'path': '/content/drive/MyDrive/Test/MODERNRES_4.pth'}\n","{'model_name': 'MODERNRES', 'seed': '5', 'path': '/content/drive/MyDrive/Test/MODERNRES_5.pth'}\n","{'model_name': 'MODERNRES', 'seed': '6', 'path': '/content/drive/MyDrive/Test/MODERNRES_6.pth'}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ypjK7N-uaSkb","executionInfo":{"status":"ok","timestamp":1765719516912,"user_tz":-60,"elapsed":1,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}}},"execution_count":134,"outputs":[]},{"cell_type":"code","source":["#initialize model helpers\n","# init model list\n","models = []\n","model_paths = [pred_model['path'] for pred_model in model_files_data]\n","print(model_paths)\n","for path in model_paths:\n","    model = MODERNRES().to(device)\n","    model.load_state_dict(torch.load(path, map_location=device))\n","    models.append(model)\n","\n","\n","# init ensem model\n","ensemble_model = EnsembleModel(models)\n","\n","# freeze parameters of individual models\n","for param in ensemble_model.parameters():\n","    param.requires_grad = False\n","\n","# unfreeze parameters of the classifier\n","for param in ensemble_model.classifier.parameters():\n","    param.requires_grad = True\n","model = ensemble_model.to(device)\n","\n","summary(model, (3, 256, 256)) # this is optional, it prints the model, its params and its trainable params.\n","\n","\n","\n","#initialize optimzer and criterion\n","# Initialize optimizer and criterion\n","params_to_update = ensemble_model.parameters()\n","optimizer = optim.AdamW(params_to_update, lr=learning_rate)\n","criterion = nn.CrossEntropyLoss()\n","\n","#train model\n","model_trained, hist = train_model(ensemble_model,\n","                          train_loader,\n","                          val_loader,\n","                          criterion,\n","                          optimizer,\n","                          early_stopping = early_stopping,\n","                          patience = patience,\n","                          min_delta = min_delta,\n","                          schedular=None,\n","                          num_epochs=num_epochs,\n","                          device=device)\n","torch.save(model_trained.state_dict(), f\"/content/drive/MyDrive/Test/ensemble.pth\")\n","with open(f\"/content/drive/MyDrive/Test/ensemble_acc.pkl\", \"wb\") as f:\n","    pickle.dump(hist, f)\n","\n","print(f\"Seed {seed}: model and history saved.\")\n"],"metadata":{"id":"j4zMHYkoZ46D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765723808905,"user_tz":-60,"elapsed":4291983,"user":{"displayName":"Mark Schuddeboom","userId":"03719376082377648878"}},"outputId":"21a87528-aa66-4e69-c3e0-b0d82f967d0c","collapsed":true},"execution_count":135,"outputs":[{"output_type":"stream","name":"stdout","text":["['/content/drive/MyDrive/Test/MODERNRES_0.pth', '/content/drive/MyDrive/Test/MODERNRES_1.pth', '/content/drive/MyDrive/Test/MODERNRES_2.pth', '/content/drive/MyDrive/Test/MODERNRES_3.pth', '/content/drive/MyDrive/Test/MODERNRES_4.pth', '/content/drive/MyDrive/Test/MODERNRES_5.pth', '/content/drive/MyDrive/Test/MODERNRES_6.pth']\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 256, 256]              96\n","            Conv2d-2         [-1, 32, 256, 256]             864\n","       BatchNorm2d-3         [-1, 32, 256, 256]              64\n","              ReLU-4         [-1, 32, 256, 256]               0\n","            Conv2d-5         [-1, 32, 256, 256]           9,216\n","       BatchNorm2d-6         [-1, 32, 256, 256]              64\n","            Linear-7                    [-1, 2]              66\n","              ReLU-8                    [-1, 2]               0\n","            Linear-9                   [-1, 32]              96\n","          Sigmoid-10                   [-1, 32]               0\n","          SEBlock-11         [-1, 32, 256, 256]               0\n","             ReLU-12         [-1, 32, 256, 256]               0\n","        MaxPool2d-13         [-1, 32, 128, 128]               0\n","    ResidualBlock-14         [-1, 32, 128, 128]               0\n","           Conv2d-15         [-1, 64, 128, 128]           2,048\n","           Conv2d-16         [-1, 64, 128, 128]          18,432\n","      BatchNorm2d-17         [-1, 64, 128, 128]             128\n","             ReLU-18         [-1, 64, 128, 128]               0\n","           Conv2d-19         [-1, 64, 128, 128]          36,864\n","      BatchNorm2d-20         [-1, 64, 128, 128]             128\n","           Linear-21                    [-1, 4]             260\n","             ReLU-22                    [-1, 4]               0\n","           Linear-23                   [-1, 64]             320\n","          Sigmoid-24                   [-1, 64]               0\n","          SEBlock-25         [-1, 64, 128, 128]               0\n","             ReLU-26         [-1, 64, 128, 128]               0\n","        MaxPool2d-27           [-1, 64, 64, 64]               0\n","    ResidualBlock-28           [-1, 64, 64, 64]               0\n","           Conv2d-29           [-1, 96, 64, 64]           6,144\n","           Conv2d-30           [-1, 96, 64, 64]          55,296\n","      BatchNorm2d-31           [-1, 96, 64, 64]             192\n","             ReLU-32           [-1, 96, 64, 64]               0\n","           Conv2d-33           [-1, 96, 64, 64]          82,944\n","      BatchNorm2d-34           [-1, 96, 64, 64]             192\n","           Linear-35                    [-1, 6]             582\n","             ReLU-36                    [-1, 6]               0\n","           Linear-37                   [-1, 96]             672\n","          Sigmoid-38                   [-1, 96]               0\n","          SEBlock-39           [-1, 96, 64, 64]               0\n","             ReLU-40           [-1, 96, 64, 64]               0\n","        MaxPool2d-41           [-1, 96, 32, 32]               0\n","    ResidualBlock-42           [-1, 96, 32, 32]               0\n","           Conv2d-43          [-1, 128, 32, 32]          12,288\n","           Conv2d-44          [-1, 128, 32, 32]         110,592\n","      BatchNorm2d-45          [-1, 128, 32, 32]             256\n","             ReLU-46          [-1, 128, 32, 32]               0\n","           Conv2d-47          [-1, 128, 32, 32]         147,456\n","      BatchNorm2d-48          [-1, 128, 32, 32]             256\n","           Linear-49                    [-1, 8]           1,032\n","             ReLU-50                    [-1, 8]               0\n","           Linear-51                  [-1, 128]           1,152\n","          Sigmoid-52                  [-1, 128]               0\n","          SEBlock-53          [-1, 128, 32, 32]               0\n","             ReLU-54          [-1, 128, 32, 32]               0\n","        MaxPool2d-55          [-1, 128, 16, 16]               0\n","    ResidualBlock-56          [-1, 128, 16, 16]               0\n","           Conv2d-57          [-1, 160, 16, 16]          20,480\n","           Conv2d-58          [-1, 160, 16, 16]         184,320\n","      BatchNorm2d-59          [-1, 160, 16, 16]             320\n","             ReLU-60          [-1, 160, 16, 16]               0\n","           Conv2d-61          [-1, 160, 16, 16]         230,400\n","      BatchNorm2d-62          [-1, 160, 16, 16]             320\n","           Linear-63                   [-1, 10]           1,610\n","             ReLU-64                   [-1, 10]               0\n","           Linear-65                  [-1, 160]           1,760\n","          Sigmoid-66                  [-1, 160]               0\n","          SEBlock-67          [-1, 160, 16, 16]               0\n","             ReLU-68          [-1, 160, 16, 16]               0\n","        MaxPool2d-69            [-1, 160, 8, 8]               0\n","    ResidualBlock-70            [-1, 160, 8, 8]               0\n","AdaptiveAvgPool2d-71            [-1, 160, 1, 1]               0\n","          Dropout-72                  [-1, 160]               0\n","           Linear-73                  [-1, 200]          32,200\n","        MODERNRES-74                  [-1, 200]               0\n","           Conv2d-75         [-1, 32, 256, 256]              96\n","           Conv2d-76         [-1, 32, 256, 256]             864\n","      BatchNorm2d-77         [-1, 32, 256, 256]              64\n","             ReLU-78         [-1, 32, 256, 256]               0\n","           Conv2d-79         [-1, 32, 256, 256]           9,216\n","      BatchNorm2d-80         [-1, 32, 256, 256]              64\n","           Linear-81                    [-1, 2]              66\n","             ReLU-82                    [-1, 2]               0\n","           Linear-83                   [-1, 32]              96\n","          Sigmoid-84                   [-1, 32]               0\n","          SEBlock-85         [-1, 32, 256, 256]               0\n","             ReLU-86         [-1, 32, 256, 256]               0\n","        MaxPool2d-87         [-1, 32, 128, 128]               0\n","    ResidualBlock-88         [-1, 32, 128, 128]               0\n","           Conv2d-89         [-1, 64, 128, 128]           2,048\n","           Conv2d-90         [-1, 64, 128, 128]          18,432\n","      BatchNorm2d-91         [-1, 64, 128, 128]             128\n","             ReLU-92         [-1, 64, 128, 128]               0\n","           Conv2d-93         [-1, 64, 128, 128]          36,864\n","      BatchNorm2d-94         [-1, 64, 128, 128]             128\n","           Linear-95                    [-1, 4]             260\n","             ReLU-96                    [-1, 4]               0\n","           Linear-97                   [-1, 64]             320\n","          Sigmoid-98                   [-1, 64]               0\n","          SEBlock-99         [-1, 64, 128, 128]               0\n","            ReLU-100         [-1, 64, 128, 128]               0\n","       MaxPool2d-101           [-1, 64, 64, 64]               0\n","   ResidualBlock-102           [-1, 64, 64, 64]               0\n","          Conv2d-103           [-1, 96, 64, 64]           6,144\n","          Conv2d-104           [-1, 96, 64, 64]          55,296\n","     BatchNorm2d-105           [-1, 96, 64, 64]             192\n","            ReLU-106           [-1, 96, 64, 64]               0\n","          Conv2d-107           [-1, 96, 64, 64]          82,944\n","     BatchNorm2d-108           [-1, 96, 64, 64]             192\n","          Linear-109                    [-1, 6]             582\n","            ReLU-110                    [-1, 6]               0\n","          Linear-111                   [-1, 96]             672\n","         Sigmoid-112                   [-1, 96]               0\n","         SEBlock-113           [-1, 96, 64, 64]               0\n","            ReLU-114           [-1, 96, 64, 64]               0\n","       MaxPool2d-115           [-1, 96, 32, 32]               0\n","   ResidualBlock-116           [-1, 96, 32, 32]               0\n","          Conv2d-117          [-1, 128, 32, 32]          12,288\n","          Conv2d-118          [-1, 128, 32, 32]         110,592\n","     BatchNorm2d-119          [-1, 128, 32, 32]             256\n","            ReLU-120          [-1, 128, 32, 32]               0\n","          Conv2d-121          [-1, 128, 32, 32]         147,456\n","     BatchNorm2d-122          [-1, 128, 32, 32]             256\n","          Linear-123                    [-1, 8]           1,032\n","            ReLU-124                    [-1, 8]               0\n","          Linear-125                  [-1, 128]           1,152\n","         Sigmoid-126                  [-1, 128]               0\n","         SEBlock-127          [-1, 128, 32, 32]               0\n","            ReLU-128          [-1, 128, 32, 32]               0\n","       MaxPool2d-129          [-1, 128, 16, 16]               0\n","   ResidualBlock-130          [-1, 128, 16, 16]               0\n","          Conv2d-131          [-1, 160, 16, 16]          20,480\n","          Conv2d-132          [-1, 160, 16, 16]         184,320\n","     BatchNorm2d-133          [-1, 160, 16, 16]             320\n","            ReLU-134          [-1, 160, 16, 16]               0\n","          Conv2d-135          [-1, 160, 16, 16]         230,400\n","     BatchNorm2d-136          [-1, 160, 16, 16]             320\n","          Linear-137                   [-1, 10]           1,610\n","            ReLU-138                   [-1, 10]               0\n","          Linear-139                  [-1, 160]           1,760\n","         Sigmoid-140                  [-1, 160]               0\n","         SEBlock-141          [-1, 160, 16, 16]               0\n","            ReLU-142          [-1, 160, 16, 16]               0\n","       MaxPool2d-143            [-1, 160, 8, 8]               0\n","   ResidualBlock-144            [-1, 160, 8, 8]               0\n","AdaptiveAvgPool2d-145            [-1, 160, 1, 1]               0\n","         Dropout-146                  [-1, 160]               0\n","          Linear-147                  [-1, 200]          32,200\n","       MODERNRES-148                  [-1, 200]               0\n","          Conv2d-149         [-1, 32, 256, 256]              96\n","          Conv2d-150         [-1, 32, 256, 256]             864\n","     BatchNorm2d-151         [-1, 32, 256, 256]              64\n","            ReLU-152         [-1, 32, 256, 256]               0\n","          Conv2d-153         [-1, 32, 256, 256]           9,216\n","     BatchNorm2d-154         [-1, 32, 256, 256]              64\n","          Linear-155                    [-1, 2]              66\n","            ReLU-156                    [-1, 2]               0\n","          Linear-157                   [-1, 32]              96\n","         Sigmoid-158                   [-1, 32]               0\n","         SEBlock-159         [-1, 32, 256, 256]               0\n","            ReLU-160         [-1, 32, 256, 256]               0\n","       MaxPool2d-161         [-1, 32, 128, 128]               0\n","   ResidualBlock-162         [-1, 32, 128, 128]               0\n","          Conv2d-163         [-1, 64, 128, 128]           2,048\n","          Conv2d-164         [-1, 64, 128, 128]          18,432\n","     BatchNorm2d-165         [-1, 64, 128, 128]             128\n","            ReLU-166         [-1, 64, 128, 128]               0\n","          Conv2d-167         [-1, 64, 128, 128]          36,864\n","     BatchNorm2d-168         [-1, 64, 128, 128]             128\n","          Linear-169                    [-1, 4]             260\n","            ReLU-170                    [-1, 4]               0\n","          Linear-171                   [-1, 64]             320\n","         Sigmoid-172                   [-1, 64]               0\n","         SEBlock-173         [-1, 64, 128, 128]               0\n","            ReLU-174         [-1, 64, 128, 128]               0\n","       MaxPool2d-175           [-1, 64, 64, 64]               0\n","   ResidualBlock-176           [-1, 64, 64, 64]               0\n","          Conv2d-177           [-1, 96, 64, 64]           6,144\n","          Conv2d-178           [-1, 96, 64, 64]          55,296\n","     BatchNorm2d-179           [-1, 96, 64, 64]             192\n","            ReLU-180           [-1, 96, 64, 64]               0\n","          Conv2d-181           [-1, 96, 64, 64]          82,944\n","     BatchNorm2d-182           [-1, 96, 64, 64]             192\n","          Linear-183                    [-1, 6]             582\n","            ReLU-184                    [-1, 6]               0\n","          Linear-185                   [-1, 96]             672\n","         Sigmoid-186                   [-1, 96]               0\n","         SEBlock-187           [-1, 96, 64, 64]               0\n","            ReLU-188           [-1, 96, 64, 64]               0\n","       MaxPool2d-189           [-1, 96, 32, 32]               0\n","   ResidualBlock-190           [-1, 96, 32, 32]               0\n","          Conv2d-191          [-1, 128, 32, 32]          12,288\n","          Conv2d-192          [-1, 128, 32, 32]         110,592\n","     BatchNorm2d-193          [-1, 128, 32, 32]             256\n","            ReLU-194          [-1, 128, 32, 32]               0\n","          Conv2d-195          [-1, 128, 32, 32]         147,456\n","     BatchNorm2d-196          [-1, 128, 32, 32]             256\n","          Linear-197                    [-1, 8]           1,032\n","            ReLU-198                    [-1, 8]               0\n","          Linear-199                  [-1, 128]           1,152\n","         Sigmoid-200                  [-1, 128]               0\n","         SEBlock-201          [-1, 128, 32, 32]               0\n","            ReLU-202          [-1, 128, 32, 32]               0\n","       MaxPool2d-203          [-1, 128, 16, 16]               0\n","   ResidualBlock-204          [-1, 128, 16, 16]               0\n","          Conv2d-205          [-1, 160, 16, 16]          20,480\n","          Conv2d-206          [-1, 160, 16, 16]         184,320\n","     BatchNorm2d-207          [-1, 160, 16, 16]             320\n","            ReLU-208          [-1, 160, 16, 16]               0\n","          Conv2d-209          [-1, 160, 16, 16]         230,400\n","     BatchNorm2d-210          [-1, 160, 16, 16]             320\n","          Linear-211                   [-1, 10]           1,610\n","            ReLU-212                   [-1, 10]               0\n","          Linear-213                  [-1, 160]           1,760\n","         Sigmoid-214                  [-1, 160]               0\n","         SEBlock-215          [-1, 160, 16, 16]               0\n","            ReLU-216          [-1, 160, 16, 16]               0\n","       MaxPool2d-217            [-1, 160, 8, 8]               0\n","   ResidualBlock-218            [-1, 160, 8, 8]               0\n","AdaptiveAvgPool2d-219            [-1, 160, 1, 1]               0\n","         Dropout-220                  [-1, 160]               0\n","          Linear-221                  [-1, 200]          32,200\n","       MODERNRES-222                  [-1, 200]               0\n","          Conv2d-223         [-1, 32, 256, 256]              96\n","          Conv2d-224         [-1, 32, 256, 256]             864\n","     BatchNorm2d-225         [-1, 32, 256, 256]              64\n","            ReLU-226         [-1, 32, 256, 256]               0\n","          Conv2d-227         [-1, 32, 256, 256]           9,216\n","     BatchNorm2d-228         [-1, 32, 256, 256]              64\n","          Linear-229                    [-1, 2]              66\n","            ReLU-230                    [-1, 2]               0\n","          Linear-231                   [-1, 32]              96\n","         Sigmoid-232                   [-1, 32]               0\n","         SEBlock-233         [-1, 32, 256, 256]               0\n","            ReLU-234         [-1, 32, 256, 256]               0\n","       MaxPool2d-235         [-1, 32, 128, 128]               0\n","   ResidualBlock-236         [-1, 32, 128, 128]               0\n","          Conv2d-237         [-1, 64, 128, 128]           2,048\n","          Conv2d-238         [-1, 64, 128, 128]          18,432\n","     BatchNorm2d-239         [-1, 64, 128, 128]             128\n","            ReLU-240         [-1, 64, 128, 128]               0\n","          Conv2d-241         [-1, 64, 128, 128]          36,864\n","     BatchNorm2d-242         [-1, 64, 128, 128]             128\n","          Linear-243                    [-1, 4]             260\n","            ReLU-244                    [-1, 4]               0\n","          Linear-245                   [-1, 64]             320\n","         Sigmoid-246                   [-1, 64]               0\n","         SEBlock-247         [-1, 64, 128, 128]               0\n","            ReLU-248         [-1, 64, 128, 128]               0\n","       MaxPool2d-249           [-1, 64, 64, 64]               0\n","   ResidualBlock-250           [-1, 64, 64, 64]               0\n","          Conv2d-251           [-1, 96, 64, 64]           6,144\n","          Conv2d-252           [-1, 96, 64, 64]          55,296\n","     BatchNorm2d-253           [-1, 96, 64, 64]             192\n","            ReLU-254           [-1, 96, 64, 64]               0\n","          Conv2d-255           [-1, 96, 64, 64]          82,944\n","     BatchNorm2d-256           [-1, 96, 64, 64]             192\n","          Linear-257                    [-1, 6]             582\n","            ReLU-258                    [-1, 6]               0\n","          Linear-259                   [-1, 96]             672\n","         Sigmoid-260                   [-1, 96]               0\n","         SEBlock-261           [-1, 96, 64, 64]               0\n","            ReLU-262           [-1, 96, 64, 64]               0\n","       MaxPool2d-263           [-1, 96, 32, 32]               0\n","   ResidualBlock-264           [-1, 96, 32, 32]               0\n","          Conv2d-265          [-1, 128, 32, 32]          12,288\n","          Conv2d-266          [-1, 128, 32, 32]         110,592\n","     BatchNorm2d-267          [-1, 128, 32, 32]             256\n","            ReLU-268          [-1, 128, 32, 32]               0\n","          Conv2d-269          [-1, 128, 32, 32]         147,456\n","     BatchNorm2d-270          [-1, 128, 32, 32]             256\n","          Linear-271                    [-1, 8]           1,032\n","            ReLU-272                    [-1, 8]               0\n","          Linear-273                  [-1, 128]           1,152\n","         Sigmoid-274                  [-1, 128]               0\n","         SEBlock-275          [-1, 128, 32, 32]               0\n","            ReLU-276          [-1, 128, 32, 32]               0\n","       MaxPool2d-277          [-1, 128, 16, 16]               0\n","   ResidualBlock-278          [-1, 128, 16, 16]               0\n","          Conv2d-279          [-1, 160, 16, 16]          20,480\n","          Conv2d-280          [-1, 160, 16, 16]         184,320\n","     BatchNorm2d-281          [-1, 160, 16, 16]             320\n","            ReLU-282          [-1, 160, 16, 16]               0\n","          Conv2d-283          [-1, 160, 16, 16]         230,400\n","     BatchNorm2d-284          [-1, 160, 16, 16]             320\n","          Linear-285                   [-1, 10]           1,610\n","            ReLU-286                   [-1, 10]               0\n","          Linear-287                  [-1, 160]           1,760\n","         Sigmoid-288                  [-1, 160]               0\n","         SEBlock-289          [-1, 160, 16, 16]               0\n","            ReLU-290          [-1, 160, 16, 16]               0\n","       MaxPool2d-291            [-1, 160, 8, 8]               0\n","   ResidualBlock-292            [-1, 160, 8, 8]               0\n","AdaptiveAvgPool2d-293            [-1, 160, 1, 1]               0\n","         Dropout-294                  [-1, 160]               0\n","          Linear-295                  [-1, 200]          32,200\n","       MODERNRES-296                  [-1, 200]               0\n","          Conv2d-297         [-1, 32, 256, 256]              96\n","          Conv2d-298         [-1, 32, 256, 256]             864\n","     BatchNorm2d-299         [-1, 32, 256, 256]              64\n","            ReLU-300         [-1, 32, 256, 256]               0\n","          Conv2d-301         [-1, 32, 256, 256]           9,216\n","     BatchNorm2d-302         [-1, 32, 256, 256]              64\n","          Linear-303                    [-1, 2]              66\n","            ReLU-304                    [-1, 2]               0\n","          Linear-305                   [-1, 32]              96\n","         Sigmoid-306                   [-1, 32]               0\n","         SEBlock-307         [-1, 32, 256, 256]               0\n","            ReLU-308         [-1, 32, 256, 256]               0\n","       MaxPool2d-309         [-1, 32, 128, 128]               0\n","   ResidualBlock-310         [-1, 32, 128, 128]               0\n","          Conv2d-311         [-1, 64, 128, 128]           2,048\n","          Conv2d-312         [-1, 64, 128, 128]          18,432\n","     BatchNorm2d-313         [-1, 64, 128, 128]             128\n","            ReLU-314         [-1, 64, 128, 128]               0\n","          Conv2d-315         [-1, 64, 128, 128]          36,864\n","     BatchNorm2d-316         [-1, 64, 128, 128]             128\n","          Linear-317                    [-1, 4]             260\n","            ReLU-318                    [-1, 4]               0\n","          Linear-319                   [-1, 64]             320\n","         Sigmoid-320                   [-1, 64]               0\n","         SEBlock-321         [-1, 64, 128, 128]               0\n","            ReLU-322         [-1, 64, 128, 128]               0\n","       MaxPool2d-323           [-1, 64, 64, 64]               0\n","   ResidualBlock-324           [-1, 64, 64, 64]               0\n","          Conv2d-325           [-1, 96, 64, 64]           6,144\n","          Conv2d-326           [-1, 96, 64, 64]          55,296\n","     BatchNorm2d-327           [-1, 96, 64, 64]             192\n","            ReLU-328           [-1, 96, 64, 64]               0\n","          Conv2d-329           [-1, 96, 64, 64]          82,944\n","     BatchNorm2d-330           [-1, 96, 64, 64]             192\n","          Linear-331                    [-1, 6]             582\n","            ReLU-332                    [-1, 6]               0\n","          Linear-333                   [-1, 96]             672\n","         Sigmoid-334                   [-1, 96]               0\n","         SEBlock-335           [-1, 96, 64, 64]               0\n","            ReLU-336           [-1, 96, 64, 64]               0\n","       MaxPool2d-337           [-1, 96, 32, 32]               0\n","   ResidualBlock-338           [-1, 96, 32, 32]               0\n","          Conv2d-339          [-1, 128, 32, 32]          12,288\n","          Conv2d-340          [-1, 128, 32, 32]         110,592\n","     BatchNorm2d-341          [-1, 128, 32, 32]             256\n","            ReLU-342          [-1, 128, 32, 32]               0\n","          Conv2d-343          [-1, 128, 32, 32]         147,456\n","     BatchNorm2d-344          [-1, 128, 32, 32]             256\n","          Linear-345                    [-1, 8]           1,032\n","            ReLU-346                    [-1, 8]               0\n","          Linear-347                  [-1, 128]           1,152\n","         Sigmoid-348                  [-1, 128]               0\n","         SEBlock-349          [-1, 128, 32, 32]               0\n","            ReLU-350          [-1, 128, 32, 32]               0\n","       MaxPool2d-351          [-1, 128, 16, 16]               0\n","   ResidualBlock-352          [-1, 128, 16, 16]               0\n","          Conv2d-353          [-1, 160, 16, 16]          20,480\n","          Conv2d-354          [-1, 160, 16, 16]         184,320\n","     BatchNorm2d-355          [-1, 160, 16, 16]             320\n","            ReLU-356          [-1, 160, 16, 16]               0\n","          Conv2d-357          [-1, 160, 16, 16]         230,400\n","     BatchNorm2d-358          [-1, 160, 16, 16]             320\n","          Linear-359                   [-1, 10]           1,610\n","            ReLU-360                   [-1, 10]               0\n","          Linear-361                  [-1, 160]           1,760\n","         Sigmoid-362                  [-1, 160]               0\n","         SEBlock-363          [-1, 160, 16, 16]               0\n","            ReLU-364          [-1, 160, 16, 16]               0\n","       MaxPool2d-365            [-1, 160, 8, 8]               0\n","   ResidualBlock-366            [-1, 160, 8, 8]               0\n","AdaptiveAvgPool2d-367            [-1, 160, 1, 1]               0\n","         Dropout-368                  [-1, 160]               0\n","          Linear-369                  [-1, 200]          32,200\n","       MODERNRES-370                  [-1, 200]               0\n","          Conv2d-371         [-1, 32, 256, 256]              96\n","          Conv2d-372         [-1, 32, 256, 256]             864\n","     BatchNorm2d-373         [-1, 32, 256, 256]              64\n","            ReLU-374         [-1, 32, 256, 256]               0\n","          Conv2d-375         [-1, 32, 256, 256]           9,216\n","     BatchNorm2d-376         [-1, 32, 256, 256]              64\n","          Linear-377                    [-1, 2]              66\n","            ReLU-378                    [-1, 2]               0\n","          Linear-379                   [-1, 32]              96\n","         Sigmoid-380                   [-1, 32]               0\n","         SEBlock-381         [-1, 32, 256, 256]               0\n","            ReLU-382         [-1, 32, 256, 256]               0\n","       MaxPool2d-383         [-1, 32, 128, 128]               0\n","   ResidualBlock-384         [-1, 32, 128, 128]               0\n","          Conv2d-385         [-1, 64, 128, 128]           2,048\n","          Conv2d-386         [-1, 64, 128, 128]          18,432\n","     BatchNorm2d-387         [-1, 64, 128, 128]             128\n","            ReLU-388         [-1, 64, 128, 128]               0\n","          Conv2d-389         [-1, 64, 128, 128]          36,864\n","     BatchNorm2d-390         [-1, 64, 128, 128]             128\n","          Linear-391                    [-1, 4]             260\n","            ReLU-392                    [-1, 4]               0\n","          Linear-393                   [-1, 64]             320\n","         Sigmoid-394                   [-1, 64]               0\n","         SEBlock-395         [-1, 64, 128, 128]               0\n","            ReLU-396         [-1, 64, 128, 128]               0\n","       MaxPool2d-397           [-1, 64, 64, 64]               0\n","   ResidualBlock-398           [-1, 64, 64, 64]               0\n","          Conv2d-399           [-1, 96, 64, 64]           6,144\n","          Conv2d-400           [-1, 96, 64, 64]          55,296\n","     BatchNorm2d-401           [-1, 96, 64, 64]             192\n","            ReLU-402           [-1, 96, 64, 64]               0\n","          Conv2d-403           [-1, 96, 64, 64]          82,944\n","     BatchNorm2d-404           [-1, 96, 64, 64]             192\n","          Linear-405                    [-1, 6]             582\n","            ReLU-406                    [-1, 6]               0\n","          Linear-407                   [-1, 96]             672\n","         Sigmoid-408                   [-1, 96]               0\n","         SEBlock-409           [-1, 96, 64, 64]               0\n","            ReLU-410           [-1, 96, 64, 64]               0\n","       MaxPool2d-411           [-1, 96, 32, 32]               0\n","   ResidualBlock-412           [-1, 96, 32, 32]               0\n","          Conv2d-413          [-1, 128, 32, 32]          12,288\n","          Conv2d-414          [-1, 128, 32, 32]         110,592\n","     BatchNorm2d-415          [-1, 128, 32, 32]             256\n","            ReLU-416          [-1, 128, 32, 32]               0\n","          Conv2d-417          [-1, 128, 32, 32]         147,456\n","     BatchNorm2d-418          [-1, 128, 32, 32]             256\n","          Linear-419                    [-1, 8]           1,032\n","            ReLU-420                    [-1, 8]               0\n","          Linear-421                  [-1, 128]           1,152\n","         Sigmoid-422                  [-1, 128]               0\n","         SEBlock-423          [-1, 128, 32, 32]               0\n","            ReLU-424          [-1, 128, 32, 32]               0\n","       MaxPool2d-425          [-1, 128, 16, 16]               0\n","   ResidualBlock-426          [-1, 128, 16, 16]               0\n","          Conv2d-427          [-1, 160, 16, 16]          20,480\n","          Conv2d-428          [-1, 160, 16, 16]         184,320\n","     BatchNorm2d-429          [-1, 160, 16, 16]             320\n","            ReLU-430          [-1, 160, 16, 16]               0\n","          Conv2d-431          [-1, 160, 16, 16]         230,400\n","     BatchNorm2d-432          [-1, 160, 16, 16]             320\n","          Linear-433                   [-1, 10]           1,610\n","            ReLU-434                   [-1, 10]               0\n","          Linear-435                  [-1, 160]           1,760\n","         Sigmoid-436                  [-1, 160]               0\n","         SEBlock-437          [-1, 160, 16, 16]               0\n","            ReLU-438          [-1, 160, 16, 16]               0\n","       MaxPool2d-439            [-1, 160, 8, 8]               0\n","   ResidualBlock-440            [-1, 160, 8, 8]               0\n","AdaptiveAvgPool2d-441            [-1, 160, 1, 1]               0\n","         Dropout-442                  [-1, 160]               0\n","          Linear-443                  [-1, 200]          32,200\n","       MODERNRES-444                  [-1, 200]               0\n","          Conv2d-445         [-1, 32, 256, 256]              96\n","          Conv2d-446         [-1, 32, 256, 256]             864\n","     BatchNorm2d-447         [-1, 32, 256, 256]              64\n","            ReLU-448         [-1, 32, 256, 256]               0\n","          Conv2d-449         [-1, 32, 256, 256]           9,216\n","     BatchNorm2d-450         [-1, 32, 256, 256]              64\n","          Linear-451                    [-1, 2]              66\n","            ReLU-452                    [-1, 2]               0\n","          Linear-453                   [-1, 32]              96\n","         Sigmoid-454                   [-1, 32]               0\n","         SEBlock-455         [-1, 32, 256, 256]               0\n","            ReLU-456         [-1, 32, 256, 256]               0\n","       MaxPool2d-457         [-1, 32, 128, 128]               0\n","   ResidualBlock-458         [-1, 32, 128, 128]               0\n","          Conv2d-459         [-1, 64, 128, 128]           2,048\n","          Conv2d-460         [-1, 64, 128, 128]          18,432\n","     BatchNorm2d-461         [-1, 64, 128, 128]             128\n","            ReLU-462         [-1, 64, 128, 128]               0\n","          Conv2d-463         [-1, 64, 128, 128]          36,864\n","     BatchNorm2d-464         [-1, 64, 128, 128]             128\n","          Linear-465                    [-1, 4]             260\n","            ReLU-466                    [-1, 4]               0\n","          Linear-467                   [-1, 64]             320\n","         Sigmoid-468                   [-1, 64]               0\n","         SEBlock-469         [-1, 64, 128, 128]               0\n","            ReLU-470         [-1, 64, 128, 128]               0\n","       MaxPool2d-471           [-1, 64, 64, 64]               0\n","   ResidualBlock-472           [-1, 64, 64, 64]               0\n","          Conv2d-473           [-1, 96, 64, 64]           6,144\n","          Conv2d-474           [-1, 96, 64, 64]          55,296\n","     BatchNorm2d-475           [-1, 96, 64, 64]             192\n","            ReLU-476           [-1, 96, 64, 64]               0\n","          Conv2d-477           [-1, 96, 64, 64]          82,944\n","     BatchNorm2d-478           [-1, 96, 64, 64]             192\n","          Linear-479                    [-1, 6]             582\n","            ReLU-480                    [-1, 6]               0\n","          Linear-481                   [-1, 96]             672\n","         Sigmoid-482                   [-1, 96]               0\n","         SEBlock-483           [-1, 96, 64, 64]               0\n","            ReLU-484           [-1, 96, 64, 64]               0\n","       MaxPool2d-485           [-1, 96, 32, 32]               0\n","   ResidualBlock-486           [-1, 96, 32, 32]               0\n","          Conv2d-487          [-1, 128, 32, 32]          12,288\n","          Conv2d-488          [-1, 128, 32, 32]         110,592\n","     BatchNorm2d-489          [-1, 128, 32, 32]             256\n","            ReLU-490          [-1, 128, 32, 32]               0\n","          Conv2d-491          [-1, 128, 32, 32]         147,456\n","     BatchNorm2d-492          [-1, 128, 32, 32]             256\n","          Linear-493                    [-1, 8]           1,032\n","            ReLU-494                    [-1, 8]               0\n","          Linear-495                  [-1, 128]           1,152\n","         Sigmoid-496                  [-1, 128]               0\n","         SEBlock-497          [-1, 128, 32, 32]               0\n","            ReLU-498          [-1, 128, 32, 32]               0\n","       MaxPool2d-499          [-1, 128, 16, 16]               0\n","   ResidualBlock-500          [-1, 128, 16, 16]               0\n","          Conv2d-501          [-1, 160, 16, 16]          20,480\n","          Conv2d-502          [-1, 160, 16, 16]         184,320\n","     BatchNorm2d-503          [-1, 160, 16, 16]             320\n","            ReLU-504          [-1, 160, 16, 16]               0\n","          Conv2d-505          [-1, 160, 16, 16]         230,400\n","     BatchNorm2d-506          [-1, 160, 16, 16]             320\n","          Linear-507                   [-1, 10]           1,610\n","            ReLU-508                   [-1, 10]               0\n","          Linear-509                  [-1, 160]           1,760\n","         Sigmoid-510                  [-1, 160]               0\n","         SEBlock-511          [-1, 160, 16, 16]               0\n","            ReLU-512          [-1, 160, 16, 16]               0\n","       MaxPool2d-513            [-1, 160, 8, 8]               0\n","   ResidualBlock-514            [-1, 160, 8, 8]               0\n","AdaptiveAvgPool2d-515            [-1, 160, 1, 1]               0\n","         Dropout-516                  [-1, 160]               0\n","          Linear-517                  [-1, 200]          32,200\n","       MODERNRES-518                  [-1, 200]               0\n","         Dropout-519                 [-1, 1400]               0\n","          Linear-520                  [-1, 200]         280,200\n","================================================================\n","Total params: 6,993,970\n","Trainable params: 280,200\n","Non-trainable params: 6,713,770\n","----------------------------------------------------------------\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 1684.70\n","Params size (MB): 26.68\n","Estimated Total Size (MB): 1712.13\n","----------------------------------------------------------------\n","Epoch 1/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 18.0981 Acc: 0.2525\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 20.0225 Acc: 0.1947\n","Validation improved (0.0000 → 0.1947)\n","\n","Epoch 2/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 7.6854 Acc: 0.5467\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 22.2941 Acc: 0.2354\n","Validation improved (0.1947 → 0.2354)\n","\n","Epoch 3/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 5.8688 Acc: 0.6508\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 25.2038 Acc: 0.2417\n","Validation improved (0.2354 → 0.2417)\n","\n","Epoch 4/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 5.1169 Acc: 0.6995\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 26.7546 Acc: 0.2468\n","Validation improved (0.2417 → 0.2468)\n","\n","Epoch 5/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.8485 Acc: 0.7324\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 29.5831 Acc: 0.2392\n","No improvement for 1 epoch(s).\n","\n","Epoch 6/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.5614 Acc: 0.7487\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 32.7901 Acc: 0.2494\n","Validation improved (0.2468 → 0.2494)\n","\n","Epoch 7/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.2745 Acc: 0.7773\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 35.0556 Acc: 0.2684\n","Validation improved (0.2494 → 0.2684)\n","\n","Epoch 8/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.4411 Acc: 0.7842\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 35.8627 Acc: 0.2481\n","No improvement for 1 epoch(s).\n","\n","Epoch 9/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.1602 Acc: 0.7989\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 36.9924 Acc: 0.2748\n","Validation improved (0.2684 → 0.2748)\n","\n","Epoch 10/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.1445 Acc: 0.8054\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 38.3315 Acc: 0.2748\n","No improvement for 1 epoch(s).\n","\n","Epoch 11/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.1847 Acc: 0.8125\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 41.2578 Acc: 0.2595\n","No improvement for 2 epoch(s).\n","\n","Epoch 12/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.2177 Acc: 0.8151\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 43.2808 Acc: 0.2621\n","No improvement for 3 epoch(s).\n","\n","Epoch 13/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.1622 Acc: 0.8245\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 45.7961 Acc: 0.2723\n","No improvement for 4 epoch(s).\n","\n","Epoch 14/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.0491 Acc: 0.8307\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 47.3449 Acc: 0.2621\n","No improvement for 5 epoch(s).\n","\n","Epoch 15/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.0058 Acc: 0.8381\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 48.8797 Acc: 0.2748\n","No improvement for 6 epoch(s).\n","\n","Epoch 16/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.0482 Acc: 0.8419\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 50.9665 Acc: 0.2634\n","No improvement for 7 epoch(s).\n","\n","Epoch 17/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.1341 Acc: 0.8407\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 48.9070 Acc: 0.2659\n","No improvement for 8 epoch(s).\n","\n","Epoch 18/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.0648 Acc: 0.8499\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 52.2020 Acc: 0.2735\n","No improvement for 9 epoch(s).\n","\n","Epoch 19/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.0663 Acc: 0.8494\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 54.7500 Acc: 0.2646\n","No improvement for 10 epoch(s).\n","\n","Epoch 20/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 3.9553 Acc: 0.8588\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 56.4520 Acc: 0.2748\n","No improvement for 11 epoch(s).\n","\n","Epoch 21/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.0703 Acc: 0.8566\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 58.6838 Acc: 0.2774\n","Validation improved (0.2748 → 0.2774)\n","\n","Epoch 22/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 3.8642 Acc: 0.8607\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 56.8934 Acc: 0.2837\n","Validation improved (0.2774 → 0.2837)\n","\n","Epoch 23/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 3.9583 Acc: 0.8667\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 59.4660 Acc: 0.2799\n","No improvement for 1 epoch(s).\n","\n","Epoch 24/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 3.9875 Acc: 0.8627\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 59.3680 Acc: 0.2913\n","Validation improved (0.2837 → 0.2913)\n","\n","Epoch 25/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 3.8263 Acc: 0.8690\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 62.9398 Acc: 0.2863\n","No improvement for 1 epoch(s).\n","\n","Epoch 26/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 3.9548 Acc: 0.8670\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 62.4745 Acc: 0.2697\n","No improvement for 2 epoch(s).\n","\n","Epoch 27/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 3.8496 Acc: 0.8721\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 66.4044 Acc: 0.2850\n","No improvement for 3 epoch(s).\n","\n","Epoch 28/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 3.9701 Acc: 0.8743\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 67.4483 Acc: 0.2595\n","No improvement for 4 epoch(s).\n","\n","Epoch 29/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 4.2590 Acc: 0.8651\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 64.9944 Acc: 0.2850\n","No improvement for 5 epoch(s).\n","\n","Epoch 30/30\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 313/313 [02:17<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 3.6547 Acc: 0.8825\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13/13 [00:05<00:00,  2.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["val Loss: 68.1277 Acc: 0.2672\n","No improvement for 6 epoch(s).\n","\n","Training complete in 71m 32s\n","Best val Acc: 0.2913\n","Seed 6: model and history saved.\n"]}]}]}