{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision import transforms \n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageEnhance \n",
    "#library for image processing in Python. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328637df",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This is where we preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bdf34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49f002ee",
   "metadata": {},
   "source": [
    "### Load in data from directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b633d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = pd.read_csv(\"train_images.csv\")\n",
    "\n",
    "rgb_img = 0\n",
    "for x in paths[\"image_path\"]:\n",
    "    # The dot makes it so that it's relative to your current dir,\n",
    "    rgb_img = plt.imread(\".\" + x)\n",
    "\n",
    "plt.imshow(rgb_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fab5a8",
   "metadata": {},
   "source": [
    "### Some exploration of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp \n",
    "\n",
    "data = pd.read_csv(\"/Users/micolcandoni/Documents/GitHub/AppliedMLProject/aml-2025-feathers-in-focus/train_images.csv\")\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "#count how many images per label \n",
    "\n",
    "counts_labels = data['label'].value_counts().sort_index().reset_index()\n",
    "counts_labels.columns = ['Label', 'Count']\n",
    "\n",
    "\n",
    "for i in counts_labels.iterrows():\n",
    "    print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12609c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6457bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts_labels['Label'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viualise counts in a plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (15, 4))\n",
    "plt.bar(counts_labels['Label'], counts_labels['Count'], color = 'violet')\n",
    "plt.title(\"Number of Images per Bird Class\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd738bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'].value_counts().head()      # Most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'].value_counts().tail()      # Least common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21211a5",
   "metadata": {},
   "source": [
    "### Make sure all data is in the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf529e34",
   "metadata": {},
   "source": [
    "### Potentially Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c27ec3d",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598fc1e0",
   "metadata": {},
   "source": [
    "### Downloaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbdcbb",
   "metadata": {},
   "source": [
    "### Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1241dc",
   "metadata": {},
   "source": [
    "### Complex model (enseble methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd0d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8cf80c",
   "metadata": {},
   "source": [
    "# Comparing models\n",
    "Here we need to decide what metric to use in order to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0952ab",
   "metadata": {},
   "source": [
    "## Data Augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85dd719",
   "metadata": {},
   "source": [
    "> Creating a validation set (from train_images.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0133dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, validate_data = train_test_split(\n",
    "    data,\n",
    "    test_size=0.2,\n",
    "    stratify= data['label'],\n",
    "    #to ensure that each bird class is represented fairly in both splits\n",
    "    random_state= 42\n",
    ")\n",
    "\n",
    "train_data.to_csv(\"train_split.csv\", index=False)\n",
    "validate_data.to_csv(\"validate_split.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validate_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.size)\n",
    "print(validate_data.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9520a0",
   "metadata": {},
   "source": [
    "> Printed to make sure that the dataset was correctly split (and to see what it looks like).\n",
    "\n",
    "- Full dataset size: 7852\n",
    "- Train set size: 6280\n",
    "- Validate set size: 1572\n",
    "\n",
    "> Now I will compute some Basic Image Data Augmentations on my train set, specifically Image Manipulation (ex:rotation, translation, shearing, flipping, cropping, noise injection, and colour space).\n",
    "\n",
    "> According to the paper, things to look out for are: overly aggressive transformations (as this can risk confusing the model), mixing across classes to create ambiguous images, and overfitting (by relying too much on augmentations). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"train_split.csv\")\n",
    "\n",
    "augmentation_output = \"augmented_set\"\n",
    "os.makedirs(augmentation_output, exist_ok=True)\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "\n",
    "\n",
    "def rotate(img, degrees = 15):\n",
    "    return img.rotate(degrees)\n",
    "#rotate the image by 15 degrees\n",
    "\n",
    "\n",
    "def flip(img):\n",
    "    return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "#flip image horizontally\n",
    "\n",
    "\n",
    "def brighten(img, factor = 1.3):\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    return enhancer.enhance(factor)\n",
    "#increase brightness\n",
    "\n",
    "\n",
    "def addnoise(img, amount = 10):\n",
    "    array = np.array(img).astype(np.int16)\n",
    "    noise = np.random.randint(-amount, amount, array.shape)\n",
    "    array = np.clip(array + noise, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(array)\n",
    "#add random noise (small)\n",
    "\n",
    "\n",
    "def translate(img, shiftx = 15, shifty = 10):\n",
    "    return img.transform(\n",
    "        img.size, \n",
    "        Image.AFFINE,\n",
    "        (1, 0, shiftx, 0, 1, shifty),\n",
    "        resample = Image.BICUBIC,\n",
    "        fillcolor = (0, 0, 0)\n",
    "    )\n",
    "#do translations (shift the image slightly as shown in the paper)\n",
    "\n",
    "\n",
    "#create dictionary:\n",
    "augmentations = {\n",
    "    \"rotate\": lambda img: rotate(img, 15),\n",
    "    \"flip\": lambda img: flip(img),\n",
    "    \"brighten\": lambda img: brighten(img, 1.3),\n",
    "    \"noise\": lambda img: addnoise(img),\n",
    "    \"translate\": lambda img: translate(img, 15, 10)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#applying the 5 augmentation techniques to create new images (increase dataset size)\n",
    "\n",
    "for index, row, in train_set.iterrows():\n",
    "    image_path = row[\"image_path\"].lstrip(\"/\")\n",
    "    label = row[\"label\"]\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    base_name = os.path.basename(image_path)\n",
    "    name, extension = os.path.splitext(base_name)\n",
    "\n",
    "\n",
    "    for augmented_name, augmented_function in augmentations.items():\n",
    "        augmented_image = augmented_function(image)\n",
    "        newfile = f\"{name}_{augmented_name}{extension}\"\n",
    "        newpath = f\"{augmentation_output}/{newfile}\"\n",
    "\n",
    "        augmented_image.save(newpath)\n",
    "\n",
    "        new_rows.append({\n",
    "            \"image_path\": newpath,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "#combining the original images + new rows to create bigger dataset\n",
    "\n",
    "augmenteddf = pd.DataFrame(new_rows)\n",
    "newdf = pd.concat([train_set, augmenteddf], ignore_index=True)\n",
    "\n",
    "newdf.to_csv(\"train_augmented.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newdf.head())\n",
    "print(newdf.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b330611",
   "metadata": {},
   "source": [
    "> printed to see what my new df looks like. Size is 37680, which confirms that augmentations worked correctly. \n",
    "\n",
    ">Initial amount = 6280 x 5 = 31400 + 6280 (original) = 37680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e14dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_augmented.csv\")\n",
    "\n",
    "# Remove leading slash ONLY \n",
    "df[\"image_path\"] = df[\"image_path\"].str.lstrip(\"/\")\n",
    "\n",
    "df.to_csv(\"train_augmented.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a176386",
   "metadata": {},
   "source": [
    "> Now I can randomly select a picture and generate the augmentations to see how the augmentations look like compared to the original. Every time I run, a new image will be selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "df = pd.read_csv(\"train_augmented.csv\")\n",
    "\n",
    "#Pick a random ORIGINAL image from train_set only (not from augmented_set)\n",
    "df_original_only = df[df[\"image_path\"].str.contains(\"train_images\")]\n",
    "random_row = df_original_only.sample(1).iloc[0]\n",
    "\n",
    "orig_path = random_row[\"image_path\"]\n",
    "label = random_row[\"label\"]\n",
    "\n",
    "#Extract base name (ex: \"1250\")\n",
    "base_name = os.path.splitext(os.path.basename(orig_path))[0]\n",
    "\n",
    "#Build expected augmented filenames\n",
    "aug_folder = \"augmented_set\"\n",
    "aug_versions = {\n",
    "    \"rotate\": f\"{aug_folder}/{base_name}_rotate.jpg\",\n",
    "    \"flip\": f\"{aug_folder}/{base_name}_flip.jpg\",\n",
    "    \"brighten\": f\"{aug_folder}/{base_name}_brighten.jpg\",\n",
    "    \"noise\": f\"{aug_folder}/{base_name}_noise.jpg\",\n",
    "    \"translate\": f\"{aug_folder}/{base_name}_translate.jpg\"\n",
    "}\n",
    "\n",
    "#Load images\n",
    "images = {\"original\": Image.open(orig_path).convert(\"RGB\")}\n",
    "for aug_name, path in aug_versions.items():\n",
    "    if os.path.exists(path):\n",
    "        images[aug_name] = Image.open(path).convert(\"RGB\")\n",
    "        \n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "columns = len(images)\n",
    "for i, (title, img) in enumerate(images.items(), start=1):\n",
    "    plt.subplot(1, columns, i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(title, fontsize=12)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Label: {label} â€” Base image: {base_name}\", fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
